{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# our own pipeline\n",
    "from pipelines.data_prapare import pack_data\n",
    "# from pipelines.tools import plot_intervals\n",
    "from pipelines.tools import power_band, one_signal_band_power, power_band_timeslice\n",
    "from pipelines.data_prapare import read_orginal_data, read_power_band_txt,read_features_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_source_path = \"./data/Tests_EEG_Lintao/\"\n",
    "# filename_list = os.listdir(\"./data/Tests_EEG_Lintao/\")\n",
    "# path_list = list()\n",
    "# for item in filename_list:\n",
    "#     path_list.append(os.path.join(data_source_path, item))\n",
    "\n",
    "# # alphabet_list, asl_list, alphabet_vision, alphabet_imagination, asl_vision, asl_imagination = pack_data(path_list)\n",
    "# alphabet_list, asl_list, alphabet_vision, alphabet_imagination, asl_vision, asl_imagination = read_orginal_data(path_list)\n",
    "\n",
    "# # all labels are same order\n",
    "# labels = list()\n",
    "# for item in alphabet_vision:\n",
    "#     labels.append(item[-1])\n",
    "    \n",
    "\n",
    "# bp_data_dict = read_power_band_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aat_vis, aat_img, asl_vis, asl_img = read_features_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_index</th>\n",
       "      <th>ch1_min</th>\n",
       "      <th>ch1_max</th>\n",
       "      <th>ch1_std</th>\n",
       "      <th>ch1_mean</th>\n",
       "      <th>ch1_coefficient_variation</th>\n",
       "      <th>ch1_mean_abs</th>\n",
       "      <th>ch1_AAC</th>\n",
       "      <th>ch1_CARD</th>\n",
       "      <th>...</th>\n",
       "      <th>ch7_coherence</th>\n",
       "      <th>ch8_coherence</th>\n",
       "      <th>ch9_coherence</th>\n",
       "      <th>ch10_coherence</th>\n",
       "      <th>ch11_coherence</th>\n",
       "      <th>ch12_coherence</th>\n",
       "      <th>ch13_coherence</th>\n",
       "      <th>ch14_coherence</th>\n",
       "      <th>ch15_coherence</th>\n",
       "      <th>ch16_coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>9</td>\n",
       "      <td>-3411.345591</td>\n",
       "      <td>-3262.952359</td>\n",
       "      <td>31.367440</td>\n",
       "      <td>-3313.606131</td>\n",
       "      <td>-0.009466</td>\n",
       "      <td>3313.606131</td>\n",
       "      <td>6.992184</td>\n",
       "      <td>342.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>-3454.283292</td>\n",
       "      <td>-3334.187369</td>\n",
       "      <td>22.167027</td>\n",
       "      <td>-3374.728294</td>\n",
       "      <td>-0.006569</td>\n",
       "      <td>3374.728294</td>\n",
       "      <td>6.986747</td>\n",
       "      <td>332.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q</td>\n",
       "      <td>17</td>\n",
       "      <td>-3772.192153</td>\n",
       "      <td>-3341.965776</td>\n",
       "      <td>75.384702</td>\n",
       "      <td>-3591.181606</td>\n",
       "      <td>-0.020992</td>\n",
       "      <td>3591.181606</td>\n",
       "      <td>6.906636</td>\n",
       "      <td>413.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508136</td>\n",
       "      <td>0.509386</td>\n",
       "      <td>0.660148</td>\n",
       "      <td>0.678768</td>\n",
       "      <td>0.437121</td>\n",
       "      <td>0.62361</td>\n",
       "      <td>0.630649</td>\n",
       "      <td>0.591844</td>\n",
       "      <td>0.544863</td>\n",
       "      <td>0.530359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>-3786.139642</td>\n",
       "      <td>-3662.221570</td>\n",
       "      <td>21.228800</td>\n",
       "      <td>-3707.487320</td>\n",
       "      <td>-0.005726</td>\n",
       "      <td>3707.487320</td>\n",
       "      <td>6.090696</td>\n",
       "      <td>334.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V</td>\n",
       "      <td>22</td>\n",
       "      <td>-3847.428125</td>\n",
       "      <td>-3682.516954</td>\n",
       "      <td>32.712980</td>\n",
       "      <td>-3751.086843</td>\n",
       "      <td>-0.008721</td>\n",
       "      <td>3751.086843</td>\n",
       "      <td>6.442441</td>\n",
       "      <td>347.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_index      ch1_min      ch1_max    ch1_std     ch1_mean  \\\n",
       "0     I            9 -3411.345591 -3262.952359  31.367440 -3313.606131   \n",
       "1     F            6 -3454.283292 -3334.187369  22.167027 -3374.728294   \n",
       "2     Q           17 -3772.192153 -3341.965776  75.384702 -3591.181606   \n",
       "3     D            4 -3786.139642 -3662.221570  21.228800 -3707.487320   \n",
       "4     V           22 -3847.428125 -3682.516954  32.712980 -3751.086843   \n",
       "\n",
       "   ch1_coefficient_variation  ch1_mean_abs   ch1_AAC  ch1_CARD  ...  \\\n",
       "0                  -0.009466   3313.606131  6.992184     342.0  ...   \n",
       "1                  -0.006569   3374.728294  6.986747     332.0  ...   \n",
       "2                  -0.020992   3591.181606  6.906636     413.0  ...   \n",
       "3                  -0.005726   3707.487320  6.090696     334.0  ...   \n",
       "4                  -0.008721   3751.086843  6.442441     347.0  ...   \n",
       "\n",
       "   ch7_coherence  ch8_coherence  ch9_coherence  ch10_coherence  \\\n",
       "0       1.000000       1.000000       1.000000        1.000000   \n",
       "1       1.000000       1.000000       1.000000        1.000000   \n",
       "2       0.508136       0.509386       0.660148        0.678768   \n",
       "3       1.000000       1.000000       1.000000        1.000000   \n",
       "4       1.000000       1.000000       1.000000        1.000000   \n",
       "\n",
       "   ch11_coherence  ch12_coherence  ch13_coherence  ch14_coherence  \\\n",
       "0        1.000000         1.00000        1.000000        1.000000   \n",
       "1        1.000000         1.00000        1.000000        1.000000   \n",
       "2        0.437121         0.62361        0.630649        0.591844   \n",
       "3        1.000000         1.00000        1.000000        1.000000   \n",
       "4        1.000000         1.00000        1.000000        1.000000   \n",
       "\n",
       "   ch15_coherence  ch16_coherence  \n",
       "0        1.000000        1.000000  \n",
       "1        1.000000        1.000000  \n",
       "2        0.544863        0.530359  \n",
       "3        1.000000        1.000000  \n",
       "4        1.000000        1.000000  \n",
       "\n",
       "[5 rows x 1122 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aat_vis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 832 entries, 0 to 831\n",
      "Columns: 1122 entries, label to ch16_coherence\n",
      "dtypes: float64(1120), int64(1), object(1)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "aat_vis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 832 entries, 0 to 831\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   label        832 non-null    object\n",
      " 1   label_index  832 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 19.5+ KB\n"
     ]
    }
   ],
   "source": [
    "aat_vis[['label','label_index']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So label dtype is object, a lot of processing will skip label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Values\n",
    "\n",
    "* NAN\n",
    "* INF\n",
    "\n",
    "There are a lot ways to process INF in DF, we will use NAN replace INF and give them values like max_column*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "check_nan = aat_vis.isnull().values.any()\n",
    "print(check_nan)\n",
    "\n",
    "check_nan = aat_img.isnull().values.any()\n",
    "print(check_nan)\n",
    "\n",
    "check_nan = asl_vis.isnull().values.any()\n",
    "print(check_nan)\n",
    "\n",
    "check_nan = asl_img.isnull().values.any()\n",
    "print(check_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "11\n",
      "14\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "count_inf = np.isinf(asl_img.iloc[: ,2:]).values.sum()\n",
    "print(count_inf)\n",
    "\n",
    "count_inf = np.isinf(asl_vis.iloc[: ,2:]).values.sum()\n",
    "print(count_inf)\n",
    "\n",
    "count_inf = np.isinf(aat_img.iloc[: ,2:]).values.sum()\n",
    "print(count_inf)\n",
    "\n",
    "count_inf = np.isinf(aat_vis.iloc[: ,2:]).values.sum()\n",
    "print(count_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our DF, no nan, but have inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_inf(df, times = 10):\n",
    "    \n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    t = np.array(df.copy())\n",
    "    for i in range(t.shape[1]):\n",
    "        temp_col = t[:,i]\n",
    "        nan_num = np.count_nonzero(temp_col != temp_col) \n",
    "        if nan_num != 0: \n",
    "            temp_col_not_nan = temp_col[temp_col==temp_col]\n",
    "            temp_col[np.isnan(temp_col)] = np.max(temp_col_not_nan)*times\n",
    "    \n",
    "    return t   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aat_img_data = replace_inf(aat_img.iloc[: ,2:])\n",
    "\n",
    "# count_inf = np.isinf(aat_img_data).sum()\n",
    "# print(count_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more direct way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "inf_times = 2\n",
    "\n",
    "aat_img_data = aat_img.iloc[: ,2:].copy()\n",
    "aat_img_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "aat_img_data = aat_img_data.fillna(aat_img_data.max()*inf_times)\n",
    "count_inf = np.isinf(aat_img_data).values.sum()\n",
    "print(count_inf)\n",
    "\n",
    "aat_vis_data = aat_vis.iloc[: ,2:].copy()\n",
    "aat_vis_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "aat_vis_data = aat_vis_data.fillna(aat_vis_data.max()*inf_times)\n",
    "count_inf = np.isinf(aat_vis_data).values.sum()\n",
    "print(count_inf)\n",
    "\n",
    "asl_img_data = asl_img.iloc[: ,2:].copy()\n",
    "asl_img_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "asl_img_data = asl_img_data.fillna(asl_img_data.max()*inf_times)\n",
    "count_inf = np.isinf(asl_img_data).values.sum()\n",
    "print(count_inf)\n",
    "\n",
    "asl_vis_data = asl_vis.iloc[: ,2:].copy()\n",
    "asl_vis_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "asl_vis_data = asl_vis_data.fillna(asl_vis_data.max()*inf_times)\n",
    "count_inf = np.isinf(asl_vis_data).values.sum()\n",
    "print(count_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "check_nan = aat_vis_data.isnull().values.any()\n",
    "print(check_nan)\n",
    "\n",
    "check_nan = aat_img_data.isnull().values.any()\n",
    "print(check_nan)\n",
    "\n",
    "check_nan = asl_vis_data.isnull().values.any()\n",
    "print(check_nan)\n",
    "\n",
    "check_nan = asl_img_data.isnull().values.any()\n",
    "print(check_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check corr\n",
    "\n",
    "\n",
    "Because our feature dimension is large and there are many calculation methods, it is inevitable that many features are related to each other.\n",
    "\n",
    "For machine learning models, some models such as logistic regression are best not to have relevant features(Ok for tree models);\n",
    "\n",
    "For deep learning models, there is no such problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aat_img_corr = aat_img_data.corr()\n",
    "aat_vis_corr = aat_vis_data.corr()\n",
    "asl_img_corr = asl_img_data.corr()\n",
    "asl_vis_corr = asl_vis_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aat_img_corr = aat_img.corr()\n",
    "# aat_vis_corr = aat_vis.corr()\n",
    "# asl_img_corr = asl_img.corr()\n",
    "# asl_vis_corr = asl_vis.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch1_min</th>\n",
       "      <th>ch1_max</th>\n",
       "      <th>ch1_std</th>\n",
       "      <th>ch1_mean</th>\n",
       "      <th>ch1_coefficient_variation</th>\n",
       "      <th>ch1_mean_abs</th>\n",
       "      <th>ch1_AAC</th>\n",
       "      <th>ch1_CARD</th>\n",
       "      <th>ch1_EMAV</th>\n",
       "      <th>ch1_median</th>\n",
       "      <th>...</th>\n",
       "      <th>ch7_coherence</th>\n",
       "      <th>ch8_coherence</th>\n",
       "      <th>ch9_coherence</th>\n",
       "      <th>ch10_coherence</th>\n",
       "      <th>ch11_coherence</th>\n",
       "      <th>ch12_coherence</th>\n",
       "      <th>ch13_coherence</th>\n",
       "      <th>ch14_coherence</th>\n",
       "      <th>ch15_coherence</th>\n",
       "      <th>ch16_coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ch1_min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999507</td>\n",
       "      <td>-0.148751</td>\n",
       "      <td>0.999689</td>\n",
       "      <td>-0.721245</td>\n",
       "      <td>-0.999689</td>\n",
       "      <td>-0.223806</td>\n",
       "      <td>-0.073495</td>\n",
       "      <td>0.070328</td>\n",
       "      <td>0.999615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072479</td>\n",
       "      <td>0.076512</td>\n",
       "      <td>0.084021</td>\n",
       "      <td>0.051747</td>\n",
       "      <td>0.063271</td>\n",
       "      <td>0.075972</td>\n",
       "      <td>0.074978</td>\n",
       "      <td>0.079691</td>\n",
       "      <td>0.078802</td>\n",
       "      <td>0.083228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch1_max</th>\n",
       "      <td>0.999507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.121846</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>-0.733765</td>\n",
       "      <td>-0.999935</td>\n",
       "      <td>-0.206535</td>\n",
       "      <td>-0.067345</td>\n",
       "      <td>0.079746</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070762</td>\n",
       "      <td>0.074774</td>\n",
       "      <td>0.081656</td>\n",
       "      <td>0.049705</td>\n",
       "      <td>0.061441</td>\n",
       "      <td>0.074118</td>\n",
       "      <td>0.073034</td>\n",
       "      <td>0.077841</td>\n",
       "      <td>0.077273</td>\n",
       "      <td>0.080978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch1_std</th>\n",
       "      <td>-0.148751</td>\n",
       "      <td>-0.121846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.130183</td>\n",
       "      <td>-0.368268</td>\n",
       "      <td>0.130183</td>\n",
       "      <td>0.411241</td>\n",
       "      <td>0.249739</td>\n",
       "      <td>0.047052</td>\n",
       "      <td>-0.126404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070764</td>\n",
       "      <td>-0.062006</td>\n",
       "      <td>-0.084160</td>\n",
       "      <td>-0.071236</td>\n",
       "      <td>-0.078852</td>\n",
       "      <td>-0.071846</td>\n",
       "      <td>-0.081822</td>\n",
       "      <td>-0.058207</td>\n",
       "      <td>-0.053273</td>\n",
       "      <td>-0.073455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch1_mean</th>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>-0.130183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.730409</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.208688</td>\n",
       "      <td>-0.071417</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072313</td>\n",
       "      <td>0.076298</td>\n",
       "      <td>0.083507</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>0.063139</td>\n",
       "      <td>0.075748</td>\n",
       "      <td>0.074783</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>0.078764</td>\n",
       "      <td>0.082729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch1_coefficient_variation</th>\n",
       "      <td>-0.721245</td>\n",
       "      <td>-0.733765</td>\n",
       "      <td>-0.368268</td>\n",
       "      <td>-0.730409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730409</td>\n",
       "      <td>0.083099</td>\n",
       "      <td>-0.059166</td>\n",
       "      <td>-0.152279</td>\n",
       "      <td>-0.732381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019872</td>\n",
       "      <td>-0.022705</td>\n",
       "      <td>-0.023370</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>-0.016960</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.018021</td>\n",
       "      <td>-0.030093</td>\n",
       "      <td>-0.027219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ch1_min   ch1_max   ch1_std  ch1_mean  \\\n",
       "ch1_min                    1.000000  0.999507 -0.148751  0.999689   \n",
       "ch1_max                    0.999507  1.000000 -0.121846  0.999935   \n",
       "ch1_std                   -0.148751 -0.121846  1.000000 -0.130183   \n",
       "ch1_mean                   0.999689  0.999935 -0.130183  1.000000   \n",
       "ch1_coefficient_variation -0.721245 -0.733765 -0.368268 -0.730409   \n",
       "\n",
       "                           ch1_coefficient_variation  ch1_mean_abs   ch1_AAC  \\\n",
       "ch1_min                                    -0.721245     -0.999689 -0.223806   \n",
       "ch1_max                                    -0.733765     -0.999935 -0.206535   \n",
       "ch1_std                                    -0.368268      0.130183  0.411241   \n",
       "ch1_mean                                   -0.730409     -1.000000 -0.208688   \n",
       "ch1_coefficient_variation                   1.000000      0.730409  0.083099   \n",
       "\n",
       "                           ch1_CARD  ch1_EMAV  ch1_median  ...  ch7_coherence  \\\n",
       "ch1_min                   -0.073495  0.070328    0.999615  ...       0.072479   \n",
       "ch1_max                   -0.067345  0.079746    0.999937  ...       0.070762   \n",
       "ch1_std                    0.249739  0.047052   -0.126404  ...      -0.070764   \n",
       "ch1_mean                  -0.071417  0.084800    0.999986  ...       0.072313   \n",
       "ch1_coefficient_variation -0.059166 -0.152279   -0.732381  ...      -0.019872   \n",
       "\n",
       "                           ch8_coherence  ch9_coherence  ch10_coherence  \\\n",
       "ch1_min                         0.076512       0.084021        0.051747   \n",
       "ch1_max                         0.074774       0.081656        0.049705   \n",
       "ch1_std                        -0.062006      -0.084160       -0.071236   \n",
       "ch1_mean                        0.076298       0.083507        0.051395   \n",
       "ch1_coefficient_variation      -0.022705      -0.023370        0.005883   \n",
       "\n",
       "                           ch11_coherence  ch12_coherence  ch13_coherence  \\\n",
       "ch1_min                          0.063271        0.075972        0.074978   \n",
       "ch1_max                          0.061441        0.074118        0.073034   \n",
       "ch1_std                         -0.078852       -0.071846       -0.081822   \n",
       "ch1_mean                         0.063139        0.075748        0.074783   \n",
       "ch1_coefficient_variation        0.003655       -0.016960       -0.010455   \n",
       "\n",
       "                           ch14_coherence  ch15_coherence  ch16_coherence  \n",
       "ch1_min                          0.079691        0.078802        0.083228  \n",
       "ch1_max                          0.077841        0.077273        0.080978  \n",
       "ch1_std                         -0.058207       -0.053273       -0.073455  \n",
       "ch1_mean                         0.079432        0.078764        0.082729  \n",
       "ch1_coefficient_variation       -0.018021       -0.030093       -0.027219  \n",
       "\n",
       "[5 rows x 1120 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aat_img_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 1120)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aat_img_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_features(df_corr, threshold=0.99):\n",
    "    \n",
    "    corr_features_list = list()\n",
    "    for i in range(df_corr.shape[0]):      \n",
    "        for j in range(0, i):           \n",
    "            if np.abs(df_corr.iloc[i, j]) >= threshold and i!=j:\n",
    "                # row and column are same name order\n",
    "                # print((df_corr.columns[i], df_corr.columns[j]))\n",
    "                corr_features_list.append((df_corr.columns[i], df_corr.columns[j]))\n",
    "    \n",
    "    return set(corr_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = corr_features(aat_img_data)\n",
    "list2 = corr_features(aat_vis_data)\n",
    "list3 = corr_features(asl_img_data)\n",
    "list4 = corr_features(asl_vis_data)\n",
    "# list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245982"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227678 245982 245698 247328 247904\n"
     ]
    }
   ],
   "source": [
    "intersection_set = list(set(list1).intersection(list2, list3, list4)) \n",
    "print(len(intersection_set), len(list1), len(list2), len(list3), len(list4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ch15_MAP', 'ch5_mean_energy')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_set[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of feature pair are high correlated.\n",
    "\n",
    "We could:\n",
    "\n",
    "1. keep just one feature in the related features list;\n",
    "2. just select one feature in the pair in the intersection;\n",
    "3. just select one feature in the pair for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unuse_feature_list = list()\n",
    "for item in intersection_set:\n",
    "    \n",
    "    strr1 = item[0].replace(\"ch1_\",'').replace(\"ch2_\",'').replace(\"ch3_\",'').replace(\"ch4_\",'').replace(\"ch5_\",'').replace(\"ch6_\",'')\n",
    "    strr1 = strr1.replace(\"ch7_\",'').replace(\"ch8_\",'').replace(\"ch9_\",'').replace(\"ch10_\",'').replace(\"ch11_\",'').replace(\"ch12_\",'')\n",
    "    strr1 = strr1.replace(\"ch13_\",'').replace(\"ch14_\",'').replace(\"ch15_\",'').replace(\"ch16_\",'')\n",
    "    \n",
    "    strr2 = item[1].replace(\"ch1_\",'').replace(\"ch2_\",'').replace(\"ch3_\",'').replace(\"ch4_\",'').replace(\"ch5_\",'').replace(\"ch6_\",'')\n",
    "    strr2 = strr2.replace(\"ch7_\",'').replace(\"ch8_\",'').replace(\"ch9_\",'').replace(\"ch10_\",'').replace(\"ch11_\",'').replace(\"ch12_\",'')\n",
    "    strr2 = strr2.replace(\"ch13_\",'').replace(\"ch14_\",'').replace(\"ch15_\",'').replace(\"ch16_\",'')\n",
    "    \n",
    "    if strr1 != strr2 and ((strr1, strr2) not in unuse_feature_list) and ((strr2, strr1) not in unuse_feature_list):\n",
    "        unuse_feature_list.append((strr1, strr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1604"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unuse_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mean_target_energy', 'shannon_entropy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unuse_feature_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish building list!\n"
     ]
    }
   ],
   "source": [
    "corr_list = [[unuse_feature_list[0][0], unuse_feature_list[0][1]]]\n",
    "\n",
    "for item in unuse_feature_list:\n",
    "    \n",
    "    for list_item in corr_list:\n",
    "\n",
    "        if (item[0] in list_item) and (item[1] not in list_item):\n",
    "            list_item.append(item[1])\n",
    "        elif (item[1] in list_item) and (item[0] not in list_item):\n",
    "            list_item.append(item[0])\n",
    "        elif (item[0] not in list_item) and (item[1] not in list_item):           \n",
    "            sub_list = [item[0], item[1]]\n",
    "            corr_list.append(sub_list)\n",
    "        elif (item[0] in list_item) and (item[1] in list_item):\n",
    "            break\n",
    "        break\n",
    "        \n",
    "print('Finish building list!')\n",
    "results = [set(corr_list[0])]\n",
    "for i in range(1, len(corr_list)):\n",
    "    if set(corr_list[i]).issubset(set(corr_list[0])):\n",
    "        continue\n",
    "    else:\n",
    "        results.append(set(corr_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just keep one feature in those lists, but after careful observation, we found that the power band features are also related.\n",
    "\n",
    "So in the end, don't delete the feature directly, but delete it in the original feature pair list, but this process will be a little more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Percent subtraction\n",
    "* Distance\n",
    "* Correlation coefficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent subtraction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max1 = diff/np.abs(alist1[i])\n",
    "max2 = diff/np.abs(alist2[i])\n",
    "diff = round(max(max1, max2))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting discovery, if we write code like above, there will be only 0% and 100%, which is caused by the speciality of the round function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_subtraction(alist1, alist2):\n",
    "    \n",
    "    differences = list()\n",
    "    for i in range(len(alist1)):\n",
    "        \n",
    "        diff = np.abs(alist1[i] - alist2[i])\n",
    "        \n",
    "        max1 = diff*100/np.abs(alist1[i])\n",
    "        max2 = diff*100/np.abs(alist2[i])\n",
    "        diff = round(max(max1, max2))   #  *100\n",
    "        \n",
    "        if diff >= 95:\n",
    "            differences.append(\"100%\")\n",
    "        elif 95> diff >=85:\n",
    "            differences.append(\"90%\")\n",
    "        elif 85> diff >=75:\n",
    "            differences.append(\"80%\")\n",
    "        elif 75> diff >=65:\n",
    "            differences.append(\"70%\") \n",
    "        elif 65> diff >=55:\n",
    "            differences.append(\"60%\")\n",
    "        elif 55> diff >=45:\n",
    "            differences.append(\"50%\")\n",
    "        elif 45> diff >=35:\n",
    "            differences.append(\"40%\")\n",
    "        elif 35> diff >=25:\n",
    "            differences.append(\"30%\")\n",
    "        elif 25> diff >=15:\n",
    "            differences.append(\"20%\")\n",
    "        elif 15> diff >=5:\n",
    "            differences.append(\"10%\")\n",
    "        else:\n",
    "            differences.append(\"0%\")\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean big class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "aat_img_mean = np.mean(np.array(aat_img_data), axis=0, keepdims=False)\n",
    "# aat_img_mean.shape\n",
    "\n",
    "aat_vis_mean = np.mean(np.array(aat_vis_data), axis=0, keepdims=False)\n",
    "asl_img_mean = np.mean(np.array(asl_img_data), axis=0, keepdims=False)\n",
    "asl_vis_mean = np.mean(np.array(asl_vis_data), axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare vision and imagination for alphabet/sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(percent_subtraction(aat_img_mean, aat_vis_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(percent_subtraction(asl_img_mean, asl_vis_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(percent_subtraction(aat_img_mean, asl_img_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(percent_subtraction(aat_vis_mean, asl_vis_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in theory, it is completely possible to complete 26 classifications.\n",
    "\n",
    "In addition, the results also give us another way of feature selection. If the model cannot select features well by itself, we can consider using this method to select features for machine learning model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0%</th>\n",
       "      <th>10%</th>\n",
       "      <th>20%</th>\n",
       "      <th>30%</th>\n",
       "      <th>40%</th>\n",
       "      <th>50%</th>\n",
       "      <th>60%</th>\n",
       "      <th>70%</th>\n",
       "      <th>80%</th>\n",
       "      <th>90%</th>\n",
       "      <th>100%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aat_img VS aat_vis</th>\n",
       "      <td>740</td>\n",
       "      <td>146</td>\n",
       "      <td>61</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asl_img VS asl_vis</th>\n",
       "      <td>778</td>\n",
       "      <td>137</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aat_img VS asl_img</th>\n",
       "      <td>306</td>\n",
       "      <td>198</td>\n",
       "      <td>86</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aat_vis VS asl_vis</th>\n",
       "      <td>301</td>\n",
       "      <td>193</td>\n",
       "      <td>90</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0%  10%  20%  30%  40%  50%  60%  70%  80%  90%  100%\n",
       "aat_img VS aat_vis  740  146   61   29   17   19   11    4    7    6    80\n",
       "asl_img VS asl_vis  778  137   50   23   11   13    9    5    3    6    85\n",
       "aat_img VS asl_img  306  198   86   57   30   50   46   35   26   33   253\n",
       "aat_vis VS asl_vis  301  193   90   63   32   50   40   33   17   36   265"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat dict\n",
    "\n",
    "dict1 = dict(Counter(percent_subtraction(aat_img_mean, aat_vis_mean)))\n",
    "dict2 = dict(Counter(percent_subtraction(asl_img_mean, asl_vis_mean)))\n",
    "dict3 = dict(Counter(percent_subtraction(aat_img_mean, asl_img_mean)))\n",
    "dict4 = dict(Counter(percent_subtraction(aat_vis_mean, asl_vis_mean)))\n",
    "\n",
    "com_dict = {key:[dict1[key], dict2[key], dict3[key],dict4[key]] for key in dict1.keys()}\n",
    "com_df = pd.DataFrame(com_dict, index=['aat_img VS aat_vis', 'asl_img VS asl_vis','aat_img VS asl_img','aat_vis VS asl_vis'], \n",
    "                      columns=['0%', '10%','20%','30%','40%','50%','60%','70%','80%','90%','100%'])\n",
    "com_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean alphabet vision W V A:\n",
    "\n",
    "Why W V A, because we compared MNE image for those three in the previous work.\n",
    "\n",
    "And we just want to make sure the 26 classification is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_mean_aat_vis = np.mean(np.array(aat_vis_data[aat_vis['label'] == 'W']), axis=0, keepdims=False)\n",
    "V_mean_aat_vis = np.mean(np.array(aat_vis_data[aat_vis['label'] == 'V']), axis=0, keepdims=False)\n",
    "A_mean_aat_vis = np.mean(np.array(aat_vis_data[aat_vis['label'] == 'A']), axis=0, keepdims=False)\n",
    "\n",
    "W_mean_aat_img = np.mean(np.array(aat_img_data[aat_img['label'] == 'W']), axis=0, keepdims=False)\n",
    "V_mean_aat_img = np.mean(np.array(aat_img_data[aat_img['label'] == 'V']), axis=0, keepdims=False)\n",
    "A_mean_aat_img = np.mean(np.array(aat_img_data[aat_img['label'] == 'A']), axis=0, keepdims=False)\n",
    "\n",
    "W_mean_asl_vis = np.mean(np.array(asl_vis_data[asl_vis['label'] == 'W']), axis=0, keepdims=False)\n",
    "V_mean_asl_vis = np.mean(np.array(asl_vis_data[asl_vis['label'] == 'V']), axis=0, keepdims=False)\n",
    "A_mean_asl_vis = np.mean(np.array(asl_vis_data[asl_vis['label'] == 'A']), axis=0, keepdims=False)\n",
    "\n",
    "W_mean_asl_img = np.mean(np.array(asl_img_data[asl_img['label'] == 'W']), axis=0, keepdims=False)\n",
    "V_mean_asl_img = np.mean(np.array(asl_img_data[asl_img['label'] == 'V']), axis=0, keepdims=False)\n",
    "A_mean_asl_img = np.mean(np.array(asl_img_data[asl_img['label'] == 'A']), axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0%</th>\n",
       "      <th>10%</th>\n",
       "      <th>20%</th>\n",
       "      <th>30%</th>\n",
       "      <th>40%</th>\n",
       "      <th>50%</th>\n",
       "      <th>60%</th>\n",
       "      <th>70%</th>\n",
       "      <th>80%</th>\n",
       "      <th>90%</th>\n",
       "      <th>100%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aat_vis: W V</th>\n",
       "      <td>668</td>\n",
       "      <td>199</td>\n",
       "      <td>61</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aat_vis: W A</th>\n",
       "      <td>612</td>\n",
       "      <td>247</td>\n",
       "      <td>58</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aat_vis: V A</th>\n",
       "      <td>688</td>\n",
       "      <td>193</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aat_img: W V</th>\n",
       "      <td>648</td>\n",
       "      <td>197</td>\n",
       "      <td>72</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aat_img: W A</th>\n",
       "      <td>582</td>\n",
       "      <td>265</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aat_img: V A</th>\n",
       "      <td>660</td>\n",
       "      <td>196</td>\n",
       "      <td>54</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asl_vis: W V</th>\n",
       "      <td>620</td>\n",
       "      <td>183</td>\n",
       "      <td>74</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asl_vis: W A</th>\n",
       "      <td>615</td>\n",
       "      <td>210</td>\n",
       "      <td>59</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asl_vis: V A</th>\n",
       "      <td>708</td>\n",
       "      <td>149</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asl_img: W V</th>\n",
       "      <td>608</td>\n",
       "      <td>185</td>\n",
       "      <td>79</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asl_img: W A</th>\n",
       "      <td>668</td>\n",
       "      <td>201</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asl_img: V A</th>\n",
       "      <td>650</td>\n",
       "      <td>147</td>\n",
       "      <td>65</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0%  10%  20%  30%  40%  50%  60%  70%  80%  90%  100%\n",
       "aat_vis: W V  668  199   61   27   11   17    6    9    7    5   110\n",
       "aat_vis: W A  612  247   58   33   10   13    9   19    3    3   113\n",
       "aat_vis: V A  688  193   50   26   18   12    4    6    9    2   112\n",
       "aat_img: W V  648  197   72   37   16   13   11   15    5    9    97\n",
       "aat_img: W A  582  265   60   25   30   11    8    9    8    6   116\n",
       "aat_img: V A  660  196   54   30   21   14    6    8    4    6   121\n",
       "asl_vis: W V  620  183   74   22   23   11   15   14    9    8   141\n",
       "asl_vis: W A  615  210   59   24   23   18   15    8    9    4   135\n",
       "asl_vis: V A  708  149   58   41   18   12    7    4    6    2   115\n",
       "asl_img: W V  608  185   79   21   22   19   13   11    4    1   157\n",
       "asl_img: W A  668  201   40   26   28   16   10    6    8    9   108\n",
       "asl_img: V A  650  147   65   38   25   15   13    5    7    5   150"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = dict(Counter(percent_subtraction(W_mean_aat_vis, V_mean_aat_vis)))\n",
    "dict2 = dict(Counter(percent_subtraction(W_mean_aat_vis, A_mean_aat_vis)))\n",
    "dict3 = dict(Counter(percent_subtraction(A_mean_aat_vis, V_mean_aat_vis)))\n",
    "dict4 = dict(Counter(percent_subtraction(W_mean_aat_img, V_mean_aat_img)))\n",
    "dict5 = dict(Counter(percent_subtraction(W_mean_aat_img, A_mean_aat_img)))\n",
    "dict6 = dict(Counter(percent_subtraction(A_mean_aat_img, V_mean_aat_img)))\n",
    "dict7 = dict(Counter(percent_subtraction(W_mean_asl_vis, V_mean_asl_vis)))\n",
    "dict8 = dict(Counter(percent_subtraction(W_mean_asl_vis, A_mean_asl_vis)))\n",
    "dict9 = dict(Counter(percent_subtraction(A_mean_asl_vis, V_mean_asl_vis)))\n",
    "dict10 = dict(Counter(percent_subtraction(W_mean_asl_img, V_mean_asl_img)))\n",
    "dict11 = dict(Counter(percent_subtraction(W_mean_asl_img, A_mean_asl_img)))\n",
    "dict12 = dict(Counter(percent_subtraction(A_mean_asl_img, V_mean_asl_img)))\n",
    "\n",
    "com_dict = {key:[dict1[key], dict2[key], dict3[key],dict4[key],dict5[key],dict6[key],dict7[key],dict8[key],\n",
    "                 dict9[key],dict10[key],dict11[key],dict12[key]] for key in dict1.keys()}\n",
    "com_df = pd.DataFrame(com_dict, index=['aat_vis: W V', 'aat_vis: W A','aat_vis: V A','aat_img: W V', 'aat_img: W A','aat_img: V A',\n",
    "                                      'asl_vis: W V', 'asl_vis: W A','asl_vis: V A','asl_img: W V', 'asl_img: W A','asl_img: V A',], \n",
    "                      columns=['0%', '10%','20%','30%','40%','50%','60%','70%','80%','90%','100%'])\n",
    "com_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite the function, let's the top 5 or top 10 different features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_subtraction(alist1, alist2, feature_name_list,top_diff='all'):\n",
    "    \"\"\"\n",
    "    top_diff: could be str - all or a number\n",
    "    \"\"\"\n",
    "    differences = list()\n",
    "    top_diffs = dict()\n",
    "    for i in range(len(alist1)):\n",
    "        \n",
    "        diff = np.abs(alist1[i] - alist2[i])\n",
    "        \n",
    "        max1 = diff*100/np.abs(alist1[i])\n",
    "        max2 = diff*100/np.abs(alist2[i])\n",
    "        diff = round(max(max1, max2))   #  *100\n",
    "        \n",
    "        if diff >= 95:\n",
    "            differences.append(\"100%\")\n",
    "            top_diffs[feature_name_list[i]] = diff \n",
    "        elif 95> diff >=85:\n",
    "            differences.append(\"90%\")\n",
    "        elif 85> diff >=75:\n",
    "            differences.append(\"80%\")\n",
    "        elif 75> diff >=65:\n",
    "            differences.append(\"70%\") \n",
    "        elif 65> diff >=55:\n",
    "            differences.append(\"60%\")\n",
    "        elif 55> diff >=45:\n",
    "            differences.append(\"50%\")\n",
    "        elif 45> diff >=35:\n",
    "            differences.append(\"40%\")\n",
    "        elif 35> diff >=25:\n",
    "            differences.append(\"30%\")\n",
    "        elif 25> diff >=15:\n",
    "            differences.append(\"20%\")\n",
    "        elif 15> diff >=5:\n",
    "            differences.append(\"10%\")\n",
    "        else:\n",
    "            differences.append(\"0%\")\n",
    "    \n",
    "    # print(top_diffs.items())\n",
    "    tt = sorted(top_diffs.items(), key=lambda d: d[1], reverse=True)\n",
    "    if top_diff == 'all': \n",
    "        return differences, tt\n",
    "    elif isinstance(top_diff,int):\n",
    "        return differences, tt[0:top_diff]\n",
    "    else:\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # differences, tt = percent_subtraction(aat_img_mean, aat_vis_mean, np.array(aat_img.columns), 'all')\n",
    "# differences, tt = percent_subtraction(aat_img_mean, aat_vis_mean, np.array(aat_img.columns), 10)\n",
    "# tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# differences, tt = percent_subtraction(asl_img_mean, asl_vis_mean, np.array(aat_img.columns), 10)\n",
    "# tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differences, tt = percent_subtraction(aat_img_mean, asl_img_mean, np.array(aat_img.columns), 10)\n",
    "# tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differences, tt = percent_subtraction(aat_vis_mean, asl_vis_mean, np.array(aat_img.columns), 10)\n",
    "# tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differences, tt = percent_subtraction(W_mean_aat_vis, V_mean_aat_vis, np.array(aat_img.columns), 10)\n",
    "# tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differences, tt = percent_subtraction(A_mean_aat_vis, V_mean_aat_vis, np.array(aat_img.columns), 10)\n",
    "# tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differences, tt = percent_subtraction(W_mean_aat_vis, V_mean_aat_vis, np.array(aat_img.columns), 10)\n",
    "# tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the code commented out above, we can find that the features that appear more frequently are(>2):\n",
    "\n",
    "(There is another point to note. We have obtained the correlation of features in the previous section. We can find that some of the following features are also related to each other.)\n",
    "\n",
    "[feature name, appearance times]\n",
    "* std var 16\n",
    "* peak 12\n",
    "* svd_entropy 7\n",
    "* lyapunov_exponent 5\n",
    "* hjorth_mobility 5\n",
    "* LZC 5\n",
    "* rms 5\n",
    "\n",
    "* pb_beta 2\n",
    "* pb_theta 2\n",
    "* pb_delta 2\n",
    "* 2_max_diff  3\n",
    "* pb_gamma 3\n",
    "* LRSSV 2\n",
    "\n",
    "\n",
    "In addition, the statistical characteristics of std, and the number of peaks seem to have a large influence here, and we can reconfirm the importance of these characteristics in the model section later.\n",
    "\n",
    "Finally, we can see the existence of the power band, which is not difficult to understand why the power band is the most classic and most useful feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance\n",
    "\n",
    "When comparing features by distance, it is best to normalize the features to prevent numerical interference.\n",
    "\n",
    "In addition, considering the dimension of the feature, the calculation of some distances is not suitable for our situation.\n",
    "\n",
    "And this is just a basic observation, see some examples (W V A) of our signals, if want to get some conclusions, it's better to do this process for all labels(26 labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# [num_samples, num_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just compare the example letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "mm_data = mm.fit_transform(np.array(aat_vis_data[aat_vis['label'] == 'W']))\n",
    "W_mean_aat_vis = np.mean(mm_data, axis=0, keepdims=False)\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "mm_data = mm.fit_transform(np.array(aat_vis_data[aat_vis['label'] == 'V']))\n",
    "V_mean_aat_vis = np.mean(mm_data, axis=0, keepdims=False)\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "mm_data = mm.fit_transform(np.array(aat_vis_data[aat_vis['label'] == 'A']))\n",
    "A_mean_aat_vis = np.mean(mm_data, axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minkowski Distance\n",
    "\n",
    "Minkowski distance is typically used with param p being 1 or 2, which correspond to the Manhattan distance and the Euclidean distance, respectively. In the limiting case of p reaching infinity, we obtain the Chebyshev distance.\n",
    "\n",
    "(p < 1 may be work for high dimension features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Manhattan Distance between W V is:: 73.28459168324623\n",
      "The Manhattan Distance between W A is:: 70.12956041931734\n",
      "The Manhattan Distance between A V is:: 77.48407348500993\n",
      "\n",
      "The Euclidean Distance between W V is:: 3.3860587239875986\n",
      "The Euclidean Distance between W A is:: 3.081774937791531\n",
      "The Euclidean Distance between A V is:: 3.4698322071738823\n"
     ]
    }
   ],
   "source": [
    "# similarity\n",
    "\n",
    "p_distance = 1\n",
    "print(\"The Manhattan Distance between W V is::\",distance.minkowski(W_mean_aat_vis, V_mean_aat_vis, p_distance))\n",
    "print(\"The Manhattan Distance between W A is::\",distance.minkowski(W_mean_aat_vis, A_mean_aat_vis, p_distance))\n",
    "print(\"The Manhattan Distance between A V is::\",distance.minkowski(A_mean_aat_vis, V_mean_aat_vis, p_distance))\n",
    "\n",
    "print()\n",
    "p_distance = 2\n",
    "print(\"The Euclidean Distance between W V is::\",distance.minkowski(W_mean_aat_vis, V_mean_aat_vis, p_distance))\n",
    "print(\"The Euclidean Distance between W A is::\",distance.minkowski(W_mean_aat_vis, A_mean_aat_vis, p_distance))\n",
    "print(\"The Euclidean Distance between A V is::\",distance.minkowski(A_mean_aat_vis, V_mean_aat_vis, p_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Manhattan Distance between W V is:: 0.3251827253844168\n",
      "The Manhattan Distance between W A is:: 0.18830570326685012\n",
      "The Manhattan Distance between A V is:: 0.13687702211756667\n",
      "\n",
      "The Euclidean Distance between W V is:: 0.17425313603212692\n",
      "The Euclidean Distance between W A is:: 0.10245725459492828\n",
      "The Euclidean Distance between A V is:: 0.07263772004149686\n"
     ]
    }
   ],
   "source": [
    "# difference\n",
    "differences, tt = percent_subtraction(W_mean_aat_vis, V_mean_aat_vis, np.array(aat_img.columns))\n",
    "tt_keys1 =  [item[0] for item in tt ]\n",
    "\n",
    "differences, tt = percent_subtraction(A_mean_aat_vis, V_mean_aat_vis, np.array(aat_img.columns))\n",
    "tt_keys2 =  [item[0] for item in tt ]\n",
    "\n",
    "differences, tt = percent_subtraction(W_mean_aat_vis, A_mean_aat_vis, np.array(aat_img.columns))\n",
    "tt_keys3 =  [item[0] for item in tt ]\n",
    "\n",
    "intersection_set = list(set(tt_keys1).intersection(tt_keys2, tt_keys3)) \n",
    "\n",
    "mm = MinMaxScaler()\n",
    "mm_data = mm.fit_transform(np.array(aat_vis_data[aat_vis['label'] == 'W'][intersection_set]))\n",
    "W_mean_aat_vis_dif = np.mean(mm_data, axis=0, keepdims=False)\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "mm_data = mm.fit_transform(np.array(aat_vis_data[aat_vis['label'] == 'V'][intersection_set]))\n",
    "V_mean_aat_vis_dif = np.mean(mm_data, axis=0, keepdims=False)\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "mm_data = mm.fit_transform(np.array(aat_vis_data[aat_vis['label'] == 'A'][intersection_set]))\n",
    "A_mean_aat_vis_dif = np.mean(mm_data, axis=0, keepdims=False)\n",
    "\n",
    "# get the most different features and calculate their differences distance\n",
    "\n",
    "p_distance = 1\n",
    "print(\"The Manhattan Distance between W V is::\",distance.minkowski(W_mean_aat_vis_dif, V_mean_aat_vis_dif, p_distance))\n",
    "print(\"The Manhattan Distance between W A is::\",distance.minkowski(W_mean_aat_vis_dif, A_mean_aat_vis_dif, p_distance))\n",
    "print(\"The Manhattan Distance between A V is::\",distance.minkowski(A_mean_aat_vis_dif, V_mean_aat_vis_dif, p_distance))\n",
    "\n",
    "print()\n",
    "p_distance = 2\n",
    "print(\"The Euclidean Distance between W V is::\",distance.minkowski(W_mean_aat_vis_dif, V_mean_aat_vis_dif, p_distance))\n",
    "print(\"The Euclidean Distance between W A is::\",distance.minkowski(W_mean_aat_vis_dif, A_mean_aat_vis_dif, p_distance))\n",
    "print(\"The Euclidean Distance between A V is::\",distance.minkowski(A_mean_aat_vis_dif, V_mean_aat_vis_dif, p_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what we can find is that the average distance between vectors is not as large as we thought, so only some features are important factors for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine distance and cosine similarity\n",
    "\n",
    "cosine distance = 1 - cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cosine Distance between W V is:: 0.0245760224914513\n",
      "The Cosine Distance between W A is:: 0.02090346621240824\n",
      "The Cosine Distance between A V is:: 0.025811939904214154\n",
      "\n",
      "The Cosine Distance between W V is:: 0.009727144367590035\n",
      "The Cosine Distance between W A is:: 0.00410134449095223\n",
      "The Cosine Distance between A V is:: 0.0013194780840022347\n",
      "\n",
      "The Cosine Similarity between W V is:: 0.9754239775085487\n",
      "The Cosine Similarity between W A is:: 0.9790965337875918\n",
      "The Cosine Similarity between A V is:: 0.9741880600957858\n"
     ]
    }
   ],
   "source": [
    "# similarity distance\n",
    "print(\"The Cosine Distance between W V is::\",distance.cosine(W_mean_aat_vis, V_mean_aat_vis))\n",
    "print(\"The Cosine Distance between W A is::\",distance.cosine(W_mean_aat_vis, A_mean_aat_vis))\n",
    "print(\"The Cosine Distance between A V is::\",distance.cosine(A_mean_aat_vis, V_mean_aat_vis))\n",
    "\n",
    "print()\n",
    "# difference distance\n",
    "print(\"The Cosine Distance between W V is::\",distance.cosine(W_mean_aat_vis_dif, V_mean_aat_vis_dif))\n",
    "print(\"The Cosine Distance between W A is::\",distance.cosine(W_mean_aat_vis_dif, A_mean_aat_vis_dif))\n",
    "print(\"The Cosine Distance between A V is::\",distance.cosine(A_mean_aat_vis_dif, V_mean_aat_vis_dif))\n",
    "\n",
    "print()\n",
    "# similarity distance\n",
    "print(\"The Cosine Similarity between W V is::\",1 - distance.cosine(W_mean_aat_vis, V_mean_aat_vis))\n",
    "print(\"The Cosine Similarity between W A is::\",1 - distance.cosine(W_mean_aat_vis, A_mean_aat_vis))\n",
    "print(\"The Cosine Similarity between A V is::\",1 - distance.cosine(A_mean_aat_vis, V_mean_aat_vis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of cosine distance and similarity look even more indistinguishable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pearsonâ€‚Correlationâ€‚Coefficient\n",
    "* Spearman Correlation\n",
    "\n",
    "PS: Jaccard/Tanimoto similarity coefficient basically used for binary vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson's correlation coefficient and p-value were used to test for non-correlation.\n",
    "\n",
    "The Pearson correlation coefficient measures the linear relationship between two datasets. The calculation of the p-value relies on the assumption that each dataset is normally distributed. Like other correlation coefficients, this Pearson correlation coefficient takes a value between -1 and +1, with 0 indicating no correlation. A correlation of -1 or +1 indicates that there is a clear linear relationship. A positive correlation means that as x increases, y also increases. A negative correlation means that as x increases, y decreases.\n",
    "\n",
    "The p-value roughly represents the probability that uncorrelated system-generated datasets have a Pearson correlation at least as extreme as the data computed from those datasets.\n",
    "\n",
    "The p-value roughly represents the probability that the uncorrelated system produces datasets that are at least as extreme as the datasets computed from them.\n",
    "\n",
    "The p-value represents a test of the null hypothesis that x and y are uncorrelated (ie, the true population correlation coefficient is zero). So sample correlation coefficients close to zero (i.e. weak correlations) will tend to give you larger p-values, while coefficients close to 1 or -1 (i.e. strong positive/negative correlations) will give you smaller p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in fact, the correlation coefficient method used to compare features will not directly see the similarity and difference like our previous calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation coefficient 0.8392653232272731 \t p value 4.027412532438404e-298\n"
     ]
    }
   ],
   "source": [
    "r, p_value = pearsonr(W_mean_aat_vis, V_mean_aat_vis)\n",
    "print(\"correlation coefficient\", r, \"\\t p value\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation coefficient 0.8764135358747893 \t p value 0.0\n"
     ]
    }
   ],
   "source": [
    "r, p_value = pearsonr(W_mean_aat_vis, A_mean_aat_vis)\n",
    "print(\"correlation coefficient\", r, \"\\t p value\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation coefficient 0.845439017148939 \t p value 8.07131563634394e-307\n"
     ]
    }
   ],
   "source": [
    "r, p_value = pearsonr(A_mean_aat_vis, V_mean_aat_vis)\n",
    "print(\"correlation coefficient\", r, \"\\t p value\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation coefficient 0.8427478663390278 \t p value 5.554994252971267e-303\n"
     ]
    }
   ],
   "source": [
    "r, p_value = spearmanr(A_mean_aat_vis, V_mean_aat_vis)\n",
    "print(\"correlation coefficient\", r, \"\\t p value\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the mean features values of these example letters are strongly correlated with very small p-values.\n",
    "\n",
    "This does not seem to explain much, but the features that lead to irrelevance are likely to be our classification decision features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "When the feature dimension is large, there may be a curse of dimensionality.\n",
    "\n",
    "Therefore, we need to select appropriate features to train the model. We have the following selection methods (we prefer to let the model choose by itself, so many of the methods here will only perform a simple test, only when the model cannot select features well , that is, when the model performance is not good, we will return to this part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some methods that we could use:\n",
    "\n",
    "* Irrelevant features(between target and features)\n",
    "* Low variance features\n",
    "* P value\n",
    "* Characteristic/beta coefficient\n",
    "* High correlation features(multicollinearity)\n",
    "* No difference features\n",
    "* Variance Inflation Factor (VIF)\n",
    "* Selection based on feature importance\n",
    "* Automatic feature selection with Scikit Learn(i.e. L1 Regularization)\n",
    "* PCA, LDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some methods and codes\n",
    "P value and Characteristic/beta coefficient, they are usually suitable for regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop uncorrelated numeric features (threshold <0.2)\n",
    "# corr = abs(df.corr().loc['price'])\n",
    "# corr = corr[corr<0.2]\n",
    "# cols_to_drop = corr.index.to_list()\n",
    "# df = df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low variance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance of numeric features\n",
    "# (df.select_dtypes(include=np.number).var().astype('str'))\n",
    "\n",
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VIF\n",
    "\n",
    "Variance inflation factor (VIF) is another measure of multicollinearity. It is measured as the ratio of the overall model variance to the variance of each independent feature. A high VIF for a feature indicates that it is related to one or more other features. Based on experience:\n",
    "\n",
    "* VIF = 1 means no correlation\n",
    "* VIF = 1-5 Moderate correlation\n",
    "* VIF >5 high correlation\n",
    "\n",
    "VIF is a useful technique to eliminate multicollinearity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# # calculate VIF\n",
    "# vif = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)\n",
    "\n",
    "# # display VIFs in a table\n",
    "# index = X_train.columns.tolist()\n",
    "# vif_df = pd.DataFrame(vif, index = index, columns = ['vif']).sort_values(by = 'vif', ascending=False)\n",
    "# vif_df[vif_df['vif']<10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main methods for our case\n",
    "\n",
    "High correlation features(multicollinearity) and No difference features, we have done in the previous section;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection based on feature importance\n",
    "\n",
    "Decision trees/random forests split the data using a feature that minimizes impurity (measured as Gini Coefficient/gain or information gain). Finding the best features is a critical part of how algorithms work in classification tasks. We can access the best features through the feature_importances_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # instantiate model\n",
    "# model = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "# # fit model\n",
    "# model.fit(X,y)\n",
    "\n",
    "\n",
    "# # feature importance\n",
    "# importances = model.feature_importances_\n",
    "\n",
    "# # visualization\n",
    "# cols = X.columns(pd.DataFrame(importances, cols, columns = ['importance'])\n",
    "#                  .sort_values(by='importance', ascending=True)\n",
    "#                  .plot(kind='barh', figsize=(4,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows the importance of each feature in reducing each node/split.\n",
    "\n",
    "Since the random forest classifier has many estimators (such as 200 decision trees in the example above), confidence intervals can be used to calculate estimates of relative importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate standard deviation of feature importances\n",
    "# std = np.std([i.feature_importances_ for i in model.estimators_], axis=0)\n",
    "\n",
    "# # visualization\n",
    "# feat_with_importance = pd.Series(importances, X.columns)\n",
    "# fig, ax = plt.subplots(figsize=(12,5))\n",
    "# feat_with_importance.plot.bar(yerr=std, ax=ax)\n",
    "# ax.set_title(\"Feature importances\")\n",
    "# ax.set_ylabel(\"Mean decrease in impurity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic feature selection with Scikit Learn\n",
    "\n",
    "There is a complete module in the sklearn library that handles feature selection in just a few lines of code.\n",
    "\n",
    "There are many automated processes in sklearn, but here I will show only a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest, chi2, SelectPercentile, SelectFromModel, \n",
    "# from sklearn.feature_selection import SequentialFeatureSelector, SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chi-square based techniques\n",
    "\n",
    "Chi-square based techniques select a certain number of user-defined features (k) based on some predefined scores. These scores are determined by calculating the chi-square statistic between the x (independent) and y (dependent) variables. In sklearn, all that needs to be done is to decide how many features to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select K best features\n",
    "# X_best = SelectKBest(chi2, k=10).fit_transform(X,y)\n",
    "\n",
    "# # keep 75% top features\n",
    "# X_best = SelectPercentile(chi2, percentile = 75).fit_transform(X,y)\n",
    "\n",
    "# # number of best features\n",
    "# X_best.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regularization\n",
    "\n",
    "Regularization reduces overfitting. If you have too many features, regularization controls their effect, either by shrinking the feature coefficients (called L2 regularization) or setting some of the feature coefficients to zero (called L1 regularization).\n",
    "\n",
    "Some models have built-in L1/L2 regularization as hyperparameters to penalize features. These functions can be eliminated using the converter SelectFromModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "# model = LinearSVC(penalty= 'l1', C = 0.002, dual=False)\n",
    "# model.fit(X,y)\n",
    "\n",
    "# # select features using the meta transformer\n",
    "# selector = SelectFromModel(estimator = model, prefit=True)\n",
    "\n",
    "# X_new = selector.transform(X)\n",
    "# X_new.shape[1]\n",
    "\n",
    "\n",
    "# # names of selected features\n",
    "# feature_names = np.array(X.columns)\n",
    "# feature_names[selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sequential method\n",
    "\n",
    "The sequential method is a classic statistical technique. In this case add/remove one feature at a time and check the model performance until it is optimized for the needs.\n",
    "\n",
    "There are two variants of the sequential method. Forward selection techniques start with 0 features, then add a feature that minimizes errors; then add another feature, and so on.\n",
    "\n",
    "Backward selection works in the opposite direction. The model starts with all the included features and computes the error; it then removes one feature that can further reduce the error. Repeat this process until the desired number of features remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # instantiate model\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# # select features\n",
    "# selector = SequentialFeatureSelector(estimator=model, n_features_to_select=10, direction='backward', cv=2)\n",
    "# selector.fit_transform(X,y)\n",
    "\n",
    "# # check names of features selected\n",
    "# feature_names = np.array(X.columns)\n",
    "# feature_names[selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "The main purpose of PCA is to reduce the dimensionality of high-dimensional feature spaces. The original features are reprojected to new dimensions (i.e. principal components). The ultimate goal is to find the number of features that best explains the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # scaling data\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # fit PCA to data\n",
    "# pca = PCA()\n",
    "# pca.fit(X_scaled)\n",
    "# evr = pca.explained_variance_ratio_\n",
    "\n",
    "# # visualizing the variance explained by each principal components\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.plot(range(0, len(evr)), evr.cumsum(), marker=\"o\", linestyle=\"--\")\n",
    "# plt.xlabel(\"Number of components\")\n",
    "# plt.ylabel(\"Cumulative explained variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA\n",
    "\n",
    "In general, LDA(Linear Discriminant Analysis) is very similar to Principal Component Analysis (PCA), but unlike PCA, which finds the axis components that maximize the variance of all data, LDA is concerned with the axis components that maximize the degree of discrimination between classes.\n",
    "\n",
    "\n",
    "In a nutshell, LDA projects the feature space (multi-dimensional samples in a dataset) into a k-dimensional subspace with smaller dimensions (kâ‰¤nâˆ’1), while maintaining the information that distinguishes classes. In general, dimensionality reduction not only reduces the computational cost of classification tasks, but also reduces the error of parameter estimation, thereby avoiding overfitting.\n",
    "\n",
    "<b>PCA vs. LDA</b>\n",
    "\n",
    "Linear discriminant analysis (LDA) and principal component analysis (PCA) are both commonly used linear transformation dimensionality reduction methods. PCA is an \"unsupervised\" algorithm that doesn't care about class labels, but instead focuses on finding those directions in the dataset that maximize variance (aka \"principal components\"); LDA is \"supervised\", which computes is another class-specific direction (or linear discriminator \"device\") - these directions characterize the axes that maximize the degree of discrimination between classes.\n",
    "\n",
    "Although it sounds intuitively that LDA is better than PCA for multi-classification tasks when class information is known, this is not necessarily the case.\n",
    "\n",
    "For example, comparing the classification accuracy of image recognition tasks after PCA or LDA processing, if the number of samples is relatively small, PCA is better than LDA (PCA vs. LDA, A.M. Martinez et al., 2001). It is not uncommon to use LDA and PCA in combination. For example, PCA is used first and then LDA is used for dimensionality reduction.\n",
    "\n",
    "It should be pointed out that LDA assumes that the data obeys a normal distribution, that different features are statistically independent of each other, and that the covariance matrices of various types of data are equal. However, this only refers to the use of LDA as a classifier. When LDA is used for dimensionality reduction, even if the data does not meet these assumptions, LDA can usually achieve good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "# lda.fit(X,y)\n",
    "# X_new = lda.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
