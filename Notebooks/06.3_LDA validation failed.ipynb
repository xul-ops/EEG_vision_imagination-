{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# our own pipeline\n",
    "from pipelines.data_prapare import read_power_band_txt,read_features_table, read_signal_data\n",
    "from pipelines.ml_functions import prepare_signals,set_seed, clean_all_feature_table, print_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aat_vis, aat_img, asl_vis, asl_img = read_features_table()\n",
    "# bp_data_dict = read_power_band_txt()\n",
    "\n",
    "# 26 * 32 = 832 data\n",
    "labels_1 = np.array(aat_vis['label_index'])\n",
    "# 26 * 32 * 2= 1664 data\n",
    "labels_2 = np.concatenate((labels_1, labels_1), axis=0)\n",
    "\n",
    "\n",
    "# for the feature analyse\n",
    "col_name = list(asl_img.columns)[2:]\n",
    "# col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and clean data\n",
    "aat_vis = clean_all_feature_table(aat_vis.iloc[:, 2:])\n",
    "aat_img = clean_all_feature_table(aat_img.iloc[:, 2:])\n",
    "asl_vis = clean_all_feature_table(asl_vis.iloc[:, 2:])\n",
    "asl_img = clean_all_feature_table(asl_img.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "redefine our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_dict(x, y, model, model_name, params, Test_size):\n",
    "    \"\"\"\n",
    "    Perform 10 fold crossvalidation, fit model with train data and evaluate its performance\n",
    "    return performance dict\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    clf = GridSearchCV(model, params, cv=10)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=Test_size)\n",
    "    clf.fit(X_train, y_train)\n",
    "    params = clf.best_params_\n",
    "\n",
    "    Training_score = clf.score(X_train, y_train)\n",
    "    Score = clf.score(X_test, y_test)\n",
    "    Whole_score = clf.score(x, y)\n",
    "    cvres = clf.cv_results_\n",
    "    cvscore = cvres['mean_test_score'][clf.best_index_]\n",
    "    macro_precision, macro_recall, macro_f1_score, macro_support = \\\n",
    "        precision_recall_fscore_support(y_test, clf.predict(X_test), average='macro')\n",
    "    micro_precision, micro_recall, micro_f1_score, micro_support = \\\n",
    "        precision_recall_fscore_support(y_test, clf.predict(X_test), average='micro')\n",
    "    if not params:\n",
    "        # empty params dict\n",
    "        params = 'default'\n",
    "    # return a dictionary\n",
    "    d_info = {'Classifier': model_name, 'param': params, 'Traing score': Training_score, ' Test Score': Score,\n",
    "              'Whole score': Whole_score, 'CV Score': cvscore,\n",
    "              'Precision(Macro)': macro_precision, 'Precision(Micro)': micro_precision,\n",
    "              'Recall(Macro)': macro_recall, 'Recall(Micro)': micro_recall,\n",
    "              'F1 Score(Macro)': macro_f1_score, 'F1 Score(Micro)': micro_f1_score}\n",
    "\n",
    "    return d_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_classifiers():\n",
    "    \"\"\"\n",
    "    Initialize our machine learning classifier ---\n",
    "    where catboost and NN (neural network classification) are not initialized,\n",
    "    and most hyperparameters will take default values\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model_names = ['SVM', 'LR', 'KNN', 'GBDT', 'DT', 'AdaB', 'RF', 'XGB', 'LGB', 'Catboost', 'NN']\n",
    "\n",
    "    # the training parameters of each model\n",
    "    param_grid_svc = [{}]\n",
    "    param_grid_logistic = [{'C': [0.1], 'penalty': ['l1', 'l2']}]\n",
    "    param_grid_knn = [{}, {'n_neighbors': list(range(3, 8))}]\n",
    "    param_grid_gbdt = [{}]\n",
    "    param_grid_tree = [{}]\n",
    "    param_grid_boost = [{}]\n",
    "    param_grid_rf = [{}]\n",
    "    param_grid_xgb = [{}]\n",
    "    param_grid_lgb = [{}]\n",
    "\n",
    "    return ([(SVC(), model_names[0], param_grid_svc),\n",
    "             (LogisticRegression(), model_names[1], param_grid_logistic),\n",
    "             (KNeighborsClassifier(), model_names[2], param_grid_knn),\n",
    "             (RandomForestClassifier(), model_names[6], param_grid_rf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation LDA\n",
    "\n",
    "If we summarize the LDA idea in one sentence, that is, \"the intra-class variance is the smallest after projection, and the inter-class variance is the largest\".\n",
    "\n",
    "How to validate LDA are a real working method?\n",
    "\n",
    "* In fact, in the previous notebook, we train our LDA by all the data and then split this new features into training set and test set. But for a real word scenario, we should just use training set to train LDA machine, and when we have a new unfamiliar data, we use our LDA machine project this new data, and send it to the classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 4]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=24)\n",
    "\n",
    "data_allfeature = np.concatenate((aat_img, aat_vis), axis=0) \n",
    "x_train,x_test,y_train,y_test = train_test_split(data_allfeature,labels_2,test_size=0.3)\n",
    "\n",
    "lda.fit(x_train, y_train)\n",
    "x_train_new = lda.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 21, 32, 43, 54, 65,\n",
       "                                                      76, 87, 98, 110, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 3, 4],\n",
       "                                        'n_estimators': [20, 240, 460, 680, 900,\n",
       "                                                         1120, 1340, 1560, 1780,\n",
       "                                                         2000]},\n",
       "                   random_state=13, verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, \n",
    "                               cv = 5, verbose=2, random_state=13, n_jobs = -1)\n",
    "rf_random.fit(x_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(rf_random.best_params_)\n",
    "best_random_rf = rf_random.best_estimator_\n",
    "x_test_new = lda.transform(x_test)\n",
    "best_random_rf.score(x_test_new, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.046\n",
      "f1 score macro av: 0.028\n",
      "recall score macro av: 0.052\n",
      "precision score macro av: 0.024\n",
      "f1 score for every class:  [0.         0.07142857 0.17647059 0.07272727 0.         0.\n",
      " 0.04       0.         0.         0.         0.         0.\n",
      " 0.         0.         0.07142857 0.12698413 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.05084746\n",
      " 0.12631579 0.        ]\n",
      "recall:  [0.         0.05555556 0.15789474 0.11764706 0.         0.\n",
      " 0.11764706 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11111111 0.17391304 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.21428571\n",
      " 0.4        0.        ]\n",
      "precision:  [0.         0.1        0.2        0.05263158 0.         0.\n",
      " 0.02409639 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.05263158 0.1        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.02884615\n",
      " 0.075      0.        ]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_w, recall_w, precision_w,  f1, recall, precision = print_performance(y_test, best_random_rf.predict(x_test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance = best_random_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06929422, 0.06237054, 0.05761907, 0.04796602, 0.05130749,\n",
       "       0.05843308, 0.04654299, 0.05012194, 0.04249871, 0.04592949,\n",
       "       0.04656026, 0.03818365, 0.03620287, 0.03880467, 0.04350782,\n",
       "       0.03897015, 0.02787916, 0.03388112, 0.02378562, 0.03990698,\n",
       "       0.02457999, 0.02900164, 0.02424741, 0.02240507])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can find this is still a bad method!!!\n",
    "\n",
    "We didn't get anything in the previous notebook....\n",
    "\n",
    "Let's check if this results will be good for just one type data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=24)\n",
    "\n",
    "# data_allfeature = np.concatenate((aat_img, aat_vis), axis=0) \n",
    "x_train,x_test,y_train,y_test = train_test_split(aat_vis,labels_1,test_size=0.3)\n",
    "\n",
    "lda.fit(x_train, y_train)\n",
    "x_train_new = lda.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 21, 32, 43, 54, 65,\n",
       "                                                      76, 87, 98, 110, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 3, 4],\n",
       "                                        'n_estimators': [20, 240, 460, 680, 900,\n",
       "                                                         1120, 1340, 1560, 1780,\n",
       "                                                         2000]},\n",
       "                   random_state=13, verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier() \n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, \n",
    "                               cv = 5, verbose=2, random_state=13, n_jobs = -1)\n",
    "rf_random.fit(x_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(rf_random.best_params_)\n",
    "best_random_rf = rf_random.best_estimator_\n",
    "\n",
    "x_test_new = lda.transform(x_test)\n",
    "best_random_rf.score(x_test_new, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.048\n",
      "f1 score macro av: 0.043\n",
      "recall score macro av: 0.047\n",
      "precision score macro av: 0.048\n",
      "f1 score for every class:  [0.         0.2        0.         0.28571429 0.         0.\n",
      " 0.         0.16666667 0.         0.         0.         0.\n",
      " 0.04651163 0.04651163 0.         0.         0.         0.\n",
      " 0.         0.1        0.         0.         0.         0.19047619\n",
      " 0.07407407 0.        ]\n",
      "recall:  [0.         0.15384615 0.         0.22222222 0.         0.\n",
      " 0.         0.15384615 0.         0.         0.         0.\n",
      " 0.09090909 0.125      0.         0.         0.         0.\n",
      " 0.         0.2        0.         0.         0.         0.18181818\n",
      " 0.09090909 0.        ]\n",
      "precision:  [0.         0.28571429 0.         0.4        0.         0.\n",
      " 0.         0.18181818 0.         0.         0.         0.\n",
      " 0.03125    0.02857143 0.         0.         0.         0.\n",
      " 0.         0.06666667 0.         0.         0.         0.2\n",
      " 0.0625     0.        ]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_w, recall_w, precision_w,  f1, recall, precision = print_performance(y_test, best_random_rf.predict(x_test_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After check and validation, this is not a real good and correct method!!!\n",
    "\n",
    "But I have an assumption, if we let our DL models directly learn those LDA features, will this let our learning process more easy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
