{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare previous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# our own pipeline\n",
    "from pipelines.data_prapare import pack_data\n",
    "from pipelines.tools import plot_intervals\n",
    "from pipelines.tools import power_band, one_signal_band_power, power_band_timeslice\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_path = \"./data/Tests_EEG_Lintao/\"\n",
    "filename_list = os.listdir(\"./data/Tests_EEG_Lintao/\")\n",
    "path_list = list()\n",
    "for item in filename_list:\n",
    "    path_list.append(os.path.join(data_source_path, item))\n",
    "\n",
    "alphabet_list, asl_list, alphabet_vision, alphabet_imagination, asl_vision, asl_imagination = pack_data(path_list)\n",
    "\n",
    "# all labels are same order\n",
    "labels = list()\n",
    "for item in alphabet_vision:\n",
    "    labels.append(item[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = \"./data/EEG_features_Lintao/\"  \n",
    "bp_feature_path = feature_path + \"band_power/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_BP = (0.5,4) # (0.1,4) (0.3, 4)\n",
    "theta_BP = (4,8) \n",
    "alpha_BP = (8,13) \n",
    "beta_BP= (13,30)  # (13,32)\n",
    "gamma_BP = (30,100) # (32, 100) (32, inf)\n",
    "band_name = [\"δ\" , \"θ\" , \"α\" , \"β\" , \"γ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch1</th>\n",
       "      <th>ch2</th>\n",
       "      <th>ch3</th>\n",
       "      <th>ch4</th>\n",
       "      <th>ch5</th>\n",
       "      <th>ch6</th>\n",
       "      <th>ch7</th>\n",
       "      <th>ch8</th>\n",
       "      <th>ch9</th>\n",
       "      <th>ch10</th>\n",
       "      <th>ch11</th>\n",
       "      <th>ch12</th>\n",
       "      <th>ch13</th>\n",
       "      <th>ch14</th>\n",
       "      <th>ch15</th>\n",
       "      <th>ch16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>-3350.615901</td>\n",
       "      <td>-6455.139095</td>\n",
       "      <td>2773.650321</td>\n",
       "      <td>-117.279603</td>\n",
       "      <td>-2065.480002</td>\n",
       "      <td>-4420.459797</td>\n",
       "      <td>-4684.053920</td>\n",
       "      <td>-4490.465461</td>\n",
       "      <td>7000.633419</td>\n",
       "      <td>-1214.414980</td>\n",
       "      <td>3737.390487</td>\n",
       "      <td>10966.145809</td>\n",
       "      <td>-3555.223770</td>\n",
       "      <td>-2529.926900</td>\n",
       "      <td>-2888.582991</td>\n",
       "      <td>1203.574384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>-3354.527456</td>\n",
       "      <td>-6465.622063</td>\n",
       "      <td>2772.309217</td>\n",
       "      <td>-116.653754</td>\n",
       "      <td>-2067.178734</td>\n",
       "      <td>-4421.063295</td>\n",
       "      <td>-4684.120975</td>\n",
       "      <td>-4491.448938</td>\n",
       "      <td>7000.879288</td>\n",
       "      <td>-1209.497596</td>\n",
       "      <td>3733.747153</td>\n",
       "      <td>10953.181798</td>\n",
       "      <td>-3553.547389</td>\n",
       "      <td>-2532.318536</td>\n",
       "      <td>-2886.169003</td>\n",
       "      <td>1206.100131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>-3345.765572</td>\n",
       "      <td>-6459.832962</td>\n",
       "      <td>2773.963246</td>\n",
       "      <td>-118.061914</td>\n",
       "      <td>-2067.670473</td>\n",
       "      <td>-4421.845606</td>\n",
       "      <td>-4685.439728</td>\n",
       "      <td>-4493.237077</td>\n",
       "      <td>6992.676198</td>\n",
       "      <td>-1226.842550</td>\n",
       "      <td>3735.579996</td>\n",
       "      <td>10955.707545</td>\n",
       "      <td>-3556.676633</td>\n",
       "      <td>-2541.214531</td>\n",
       "      <td>-2889.074730</td>\n",
       "      <td>1202.903831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>-3356.047375</td>\n",
       "      <td>-6460.257645</td>\n",
       "      <td>2774.075004</td>\n",
       "      <td>-120.878234</td>\n",
       "      <td>-2062.596627</td>\n",
       "      <td>-4420.839777</td>\n",
       "      <td>-4683.942161</td>\n",
       "      <td>-4490.353702</td>\n",
       "      <td>6997.504174</td>\n",
       "      <td>-1199.171090</td>\n",
       "      <td>3735.736458</td>\n",
       "      <td>10955.394620</td>\n",
       "      <td>-3551.960415</td>\n",
       "      <td>-2521.992030</td>\n",
       "      <td>-2886.191355</td>\n",
       "      <td>1204.669619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>-3348.224264</td>\n",
       "      <td>-6460.794087</td>\n",
       "      <td>2773.672673</td>\n",
       "      <td>-115.603222</td>\n",
       "      <td>-2070.173868</td>\n",
       "      <td>-4422.247937</td>\n",
       "      <td>-4689.910077</td>\n",
       "      <td>-4494.712293</td>\n",
       "      <td>6996.274828</td>\n",
       "      <td>-1208.491767</td>\n",
       "      <td>3735.334126</td>\n",
       "      <td>10954.791123</td>\n",
       "      <td>-3553.905017</td>\n",
       "      <td>-2524.316612</td>\n",
       "      <td>-2887.666570</td>\n",
       "      <td>1203.999067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>-3339.060049</td>\n",
       "      <td>-6440.610461</td>\n",
       "      <td>2805.970944</td>\n",
       "      <td>-137.776153</td>\n",
       "      <td>-2030.119542</td>\n",
       "      <td>-4433.602623</td>\n",
       "      <td>-4729.271499</td>\n",
       "      <td>-4534.476046</td>\n",
       "      <td>7047.616785</td>\n",
       "      <td>-1237.973718</td>\n",
       "      <td>3767.967673</td>\n",
       "      <td>10911.495794</td>\n",
       "      <td>-3520.802083</td>\n",
       "      <td>-2536.766533</td>\n",
       "      <td>-2891.198145</td>\n",
       "      <td>1191.526793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>-3350.973529</td>\n",
       "      <td>-6447.427743</td>\n",
       "      <td>2804.831005</td>\n",
       "      <td>-142.782944</td>\n",
       "      <td>-2026.856187</td>\n",
       "      <td>-4434.004955</td>\n",
       "      <td>-4726.812807</td>\n",
       "      <td>-4532.084409</td>\n",
       "      <td>7048.488504</td>\n",
       "      <td>-1250.691861</td>\n",
       "      <td>3765.017243</td>\n",
       "      <td>10883.265541</td>\n",
       "      <td>-3517.359914</td>\n",
       "      <td>-2533.525531</td>\n",
       "      <td>-2887.912439</td>\n",
       "      <td>1193.761968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>-3333.270947</td>\n",
       "      <td>-6437.816493</td>\n",
       "      <td>2806.932069</td>\n",
       "      <td>-138.357298</td>\n",
       "      <td>-2033.449952</td>\n",
       "      <td>-4435.591928</td>\n",
       "      <td>-4733.853606</td>\n",
       "      <td>-4537.962918</td>\n",
       "      <td>7049.404925</td>\n",
       "      <td>-1241.818218</td>\n",
       "      <td>3765.866609</td>\n",
       "      <td>10894.776689</td>\n",
       "      <td>-3520.064476</td>\n",
       "      <td>-2524.473074</td>\n",
       "      <td>-2890.147613</td>\n",
       "      <td>1191.638552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>-3343.351584</td>\n",
       "      <td>-6443.471485</td>\n",
       "      <td>2807.110883</td>\n",
       "      <td>-140.614824</td>\n",
       "      <td>-2025.716248</td>\n",
       "      <td>-4435.524873</td>\n",
       "      <td>-4727.304545</td>\n",
       "      <td>-4533.313755</td>\n",
       "      <td>7055.529303</td>\n",
       "      <td>-1245.103925</td>\n",
       "      <td>3770.336958</td>\n",
       "      <td>10897.950637</td>\n",
       "      <td>-3516.689362</td>\n",
       "      <td>-2530.977432</td>\n",
       "      <td>-2889.164137</td>\n",
       "      <td>1190.856241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>-3343.083363</td>\n",
       "      <td>-6443.359726</td>\n",
       "      <td>2805.658019</td>\n",
       "      <td>-136.591510</td>\n",
       "      <td>-2029.784266</td>\n",
       "      <td>-4436.463646</td>\n",
       "      <td>-4730.344383</td>\n",
       "      <td>-4535.683040</td>\n",
       "      <td>7052.556521</td>\n",
       "      <td>-1220.718172</td>\n",
       "      <td>3766.067775</td>\n",
       "      <td>10899.761128</td>\n",
       "      <td>-3516.331734</td>\n",
       "      <td>-2518.371048</td>\n",
       "      <td>-2887.867735</td>\n",
       "      <td>1193.471395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ch1          ch2          ch3         ch4          ch5  \\\n",
       "2283 -3350.615901 -6455.139095  2773.650321 -117.279603 -2065.480002   \n",
       "2284 -3354.527456 -6465.622063  2772.309217 -116.653754 -2067.178734   \n",
       "2285 -3345.765572 -6459.832962  2773.963246 -118.061914 -2067.670473   \n",
       "2286 -3356.047375 -6460.257645  2774.075004 -120.878234 -2062.596627   \n",
       "2287 -3348.224264 -6460.794087  2773.672673 -115.603222 -2070.173868   \n",
       "...           ...          ...          ...         ...          ...   \n",
       "2638 -3339.060049 -6440.610461  2805.970944 -137.776153 -2030.119542   \n",
       "2639 -3350.973529 -6447.427743  2804.831005 -142.782944 -2026.856187   \n",
       "2640 -3333.270947 -6437.816493  2806.932069 -138.357298 -2033.449952   \n",
       "2641 -3343.351584 -6443.471485  2807.110883 -140.614824 -2025.716248   \n",
       "2642 -3343.083363 -6443.359726  2805.658019 -136.591510 -2029.784266   \n",
       "\n",
       "              ch6          ch7          ch8          ch9         ch10  \\\n",
       "2283 -4420.459797 -4684.053920 -4490.465461  7000.633419 -1214.414980   \n",
       "2284 -4421.063295 -4684.120975 -4491.448938  7000.879288 -1209.497596   \n",
       "2285 -4421.845606 -4685.439728 -4493.237077  6992.676198 -1226.842550   \n",
       "2286 -4420.839777 -4683.942161 -4490.353702  6997.504174 -1199.171090   \n",
       "2287 -4422.247937 -4689.910077 -4494.712293  6996.274828 -1208.491767   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "2638 -4433.602623 -4729.271499 -4534.476046  7047.616785 -1237.973718   \n",
       "2639 -4434.004955 -4726.812807 -4532.084409  7048.488504 -1250.691861   \n",
       "2640 -4435.591928 -4733.853606 -4537.962918  7049.404925 -1241.818218   \n",
       "2641 -4435.524873 -4727.304545 -4533.313755  7055.529303 -1245.103925   \n",
       "2642 -4436.463646 -4730.344383 -4535.683040  7052.556521 -1220.718172   \n",
       "\n",
       "             ch11          ch12         ch13         ch14         ch15  \\\n",
       "2283  3737.390487  10966.145809 -3555.223770 -2529.926900 -2888.582991   \n",
       "2284  3733.747153  10953.181798 -3553.547389 -2532.318536 -2886.169003   \n",
       "2285  3735.579996  10955.707545 -3556.676633 -2541.214531 -2889.074730   \n",
       "2286  3735.736458  10955.394620 -3551.960415 -2521.992030 -2886.191355   \n",
       "2287  3735.334126  10954.791123 -3553.905017 -2524.316612 -2887.666570   \n",
       "...           ...           ...          ...          ...          ...   \n",
       "2638  3767.967673  10911.495794 -3520.802083 -2536.766533 -2891.198145   \n",
       "2639  3765.017243  10883.265541 -3517.359914 -2533.525531 -2887.912439   \n",
       "2640  3765.866609  10894.776689 -3520.064476 -2524.473074 -2890.147613   \n",
       "2641  3770.336958  10897.950637 -3516.689362 -2530.977432 -2889.164137   \n",
       "2642  3766.067775  10899.761128 -3516.331734 -2518.371048 -2887.867735   \n",
       "\n",
       "             ch16  \n",
       "2283  1203.574384  \n",
       "2284  1206.100131  \n",
       "2285  1202.903831  \n",
       "2286  1204.669619  \n",
       "2287  1203.999067  \n",
       "...           ...  \n",
       "2638  1191.526793  \n",
       "2639  1193.761968  \n",
       "2640  1191.638552  \n",
       "2641  1190.856241  \n",
       "2642  1193.471395  \n",
       "\n",
       "[360 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet_1 = alphabet_vision[0]\n",
    "\n",
    "# alphabet_1\n",
    "# (0, (2283, 2642), 'vision', 'alphabet', 9, 'I')\n",
    "\n",
    "example = alphabet_list[0].iloc[2283:2643,0:16]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, some ways to generate features for model training:\n",
    "\n",
    "1. pure power band(three methods)\n",
    "2. generate own EEG image with positions(should be adapted)\n",
    "3. use MNE EEG images\n",
    "4. consider time features, use time step power band\n",
    "5. consider time features, use time step power band images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some codes are commented in the section below, they won't need to re run them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the reference that help the codes below are listed:\n",
    "\n",
    "* https://github.com/JingweiToo/EEG-Feature-Extraction-Toolbox\n",
    "\n",
    "* https://github.com/CisottoGiulia/EEG-EMG-analytics\n",
    "\n",
    "* https://github.com/yangsh827/Seizure_FE\n",
    "\n",
    "* https://github.com/sari-saba-sadiya/EEGExtract\n",
    "\n",
    "* https://github.com/N-kalaivaani-IT/EEG-Feature-Extraction\n",
    "\n",
    "* https://github.com/forrestbao/pyeeg; https://github.com/shaikhsadaf/Feature-Extraction-of-EEG-Signals\n",
    "\n",
    "* https://github.com/raphaelvallat/antropy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the references above, I got two py files for eeg features generation:\n",
    "\n",
    "1. EEGExtract.py , original code, just add a mean frequency, but some functions are duplicated, or useless\n",
    "2. eeg_features.py, a combined code, with a lot of features, but LLE are not using\n",
    "3. Non_use_fe.py, other codes, which are not using in our case\n",
    "\n",
    "But in fact, some features are produced by the normalized signals instead of the original one, otherwise, there will be some problem, but it\n",
    "doesn't matter, because before we train a model, all features will pass the sklearn normalization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipelines.EEGExtract as eeg_et\n",
    "import pipelines.eeg_features as eeg_fe \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eeg_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# # ant LZC is too slow\n",
    "# eeg_fe.LZC(np.array(example['ch1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_fe.LLE(np.array(example['ch1']),2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_fe.cardinality(np.array(example['ch12']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def eeg_feature(data, sf=125):\n",
    "    # data : 2-d array\n",
    "    result = dict()\n",
    "    mm = MinMaxScaler()\n",
    "    mm_data = mm.fit_transform(data)\n",
    "    for i in range(data.shape[-1]):\n",
    "\n",
    "        ch = data[:,i]\n",
    "        mm_ch = mm_data[:,i]\n",
    "        \n",
    "        result['ch' + str(i+1) + '_' + 'min'] =  eeg_fe.min_X(ch) \n",
    "        result['ch' + str(i+1) + '_' + 'max'] =  eeg_fe.max_X(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'std'] =  eeg_fe.std_X(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'mean'] =  eeg_fe.mean_X(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'coefficient_variation'] =  eeg_fe.coefficient_variation(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'mean_abs'] =  eeg_fe.mean_absolute_X(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'AAC'] =  eeg_fe.average_amplitude_change(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'CARD'] =  eeg_fe.cardinality(ch)\n",
    "        # print(eeg_fe.carinality(ch))\n",
    "        \n",
    "        result['ch' + str(i+1) + '_' + 'EMAV'] =  eeg_fe.enhanced_mean_absolute(mm_ch)\n",
    "        result['ch' + str(i+1) + '_' + 'median'] =  eeg_fe.median_X(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'MAP'] =  eeg_fe.mean_amplitude_power(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'signal_energy'] =  eeg_fe.signal_energy(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'mean_energy'] =  eeg_fe.mean_energy(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'waveform_length'] =  eeg_fe.waveform_length(ch)\n",
    "        \n",
    "        # all nan, pass this\n",
    "#         result['ch' + str(i+1) + '_' + 'EML'] =  eeg_fe.enhanced_wave_length(ch)\n",
    "#         print(eeg_fe.enhanced_wave_length(mm_ch))\n",
    "        \n",
    "        # sum_diff, min_diff, max_diff, mean_diff, median_diff\n",
    "        diff_1 = eeg_fe.first_order_diff(ch)\n",
    "        diff_2 = eeg_fe.second_order_diff(ch)\n",
    "        result['ch' + str(i+1) + '_' + '1_sum_diff'] =  diff_1[0]\n",
    "        result['ch' + str(i+1) + '_' + '1_min_diff'] =  diff_1[1]\n",
    "        result['ch' + str(i+1) + '_' + '1_max_diff'] =  diff_1[2]\n",
    "        result['ch' + str(i+1) + '_' + '1_mean_diff'] =  diff_1[3]\n",
    "        result['ch' + str(i+1) + '_' + '1_median_diff'] =  diff_1[4]\n",
    "        result['ch' + str(i+1) + '_' + '2_sum_diff'] =  diff_2[0]\n",
    "        result['ch' + str(i+1) + '_' + '2_min_diff'] =  diff_2[1]\n",
    "        result['ch' + str(i+1) + '_' + '2_max_diff'] =  diff_2[2]\n",
    "        result['ch' + str(i+1) + '_' + '2_mean_diff'] =  diff_2[3]\n",
    "        result['ch' + str(i+1) + '_' + '2_median_diff'] =  diff_2[4]\n",
    "\n",
    "        \n",
    "        result['ch' + str(i+1) + '_' + 'log_energy_entropy'] =  eeg_fe.log_energy_entropy(ch)\n",
    "        # very close values \n",
    "        result['ch' + str(i+1) + '_' + 'renyi_entropy'] =  eeg_fe.renyi_entropy(ch)\n",
    "        # print(eeg_fe.renyi_entropy(ch))\n",
    "        result['ch' + str(i+1) + '_' + 'LRSSV'] =  eeg_fe.log_root_sum_of_sequential_Variation(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'MCL'] =  eeg_fe.mean_curve_length(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'mean_teager_energy'] =  eeg_fe.mean_teager_energy(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'var'] =  eeg_fe.var_X(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'totalVariation'] =  eeg_fe.totalVariation(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'skew'] =  eeg_fe.skew_X(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'kurtosis'] =  eeg_fe.kurs_X(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'rms'] =  eeg_fe.rms_X(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'peak'] =  eeg_fe.peak_X(ch)\n",
    "        # closing\n",
    "        result['ch' + str(i+1) + '_' + 'PAPR'] =  eeg_fe.papr_X(ch)\n",
    "        \n",
    "#         # pEA5, pED5, pED4, pED3, pED2, pED1  wavelet; but wavelet power is not a standard power, so skip this feature for now\n",
    "#         wavelet_power = eeg_fe.relativePower(ch)\n",
    "#         result['ch' + str(i+1) + '_' + 'wavelet_power51'] =  wavelet_power[0]\n",
    "#         result['ch' + str(i+1) + '_' + 'wavelet_power52'] =  wavelet_power[1]\n",
    "#         result['ch' + str(i+1) + '_' + 'wavelet_power4'] =  wavelet_power[2]\n",
    "#         result['ch' + str(i+1) + '_' + 'wavelet_power3'] =  wavelet_power[3]\n",
    "#         result['ch' + str(i+1) + '_' + 'wavelet_power2'] =  wavelet_power[4]\n",
    "#         result['ch' + str(i+1) + '_' + 'wavelet_power1'] =  wavelet_power[5]\n",
    "        \n",
    "        result['ch' + str(i+1) + '_' + 'wavelet_entropy'] =  eeg_fe.wavelet_entopy(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'hurst'] =  eeg_fe.Hurst(ch)\n",
    "        # closing\n",
    "        result['ch' + str(i+1) + '_' + 'PFD'] =  eeg_fe.Petrosian_FD(ch)\n",
    "        \n",
    "        result['ch' + str(i+1) + '_' + 'sample_entropy'] =  eeg_fe.sample_entropy(ch)\n",
    "    \n",
    "        \n",
    "        # two different permutation_entropy, I use ant\n",
    "        PE = eeg_fe.permutation_entropy(ch)\n",
    "        # result['ch' + str(i+1) + '_' + 'pye_permutation_entropy'] =  PE[0]\n",
    "        result['ch' + str(i+1) + '_' + 'ant_permutation_entropy'] =  PE[1]\n",
    "\n",
    "\n",
    "        hjorth =  eeg_fe.Hjorth(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'hjorth_activity'] = hjorth[0]\n",
    "        result['ch' + str(i+1) + '_' + 'hjorth_mobility'] = hjorth[1]\n",
    "        result['ch' + str(i+1) + '_' + 'hjorth_complexity'] = hjorth[-1] \n",
    " \n",
    "        result['ch' + str(i+1) + '_' + 'KFD'] = eeg_fe.KFD(ch)\n",
    "    \n",
    "        # two different DFA, I use ant\n",
    "        DFA = eeg_fe.DFA(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'DFA'] = DFA[0]\n",
    "        #  result['ch' + str(i+1) + '_' + 'DFA_2'] = DFA[1]\n",
    "\n",
    "        result['ch' + str(i+1) + '_' + 'HFD'] = eeg_fe.HFD(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'shannon_entropy'] =  eeg_fe.shannon_entropy(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'spectral_entropy'] =  eeg_fe.spectral_entropy(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'approximate_entropy'] =  eeg_fe.approximate_entropy(ch)\n",
    "        result['ch' + str(i+1) + '_' + 'svd_entropy'] =  eeg_fe.svd_entropy(ch)\n",
    "        \n",
    "        # all are 0\n",
    "        result['ch' + str(i+1) + '_' + 'num_zero_crossing'] =  eeg_fe.num_zero_crossing(ch)\n",
    "        # print(eeg_fe.num_zero_crossing(ch))\n",
    "        \n",
    "        # own LZC, not ant LZC, ant LZC is too slow\n",
    "        result['ch' + str(i+1) + '_' + 'LZC'] = eeg_fe.LZC(ch)\n",
    "        # print(eeg_fe.LZC(ch))\n",
    "        \n",
    "        # welch power band\n",
    "        pb = one_signal_band_power(ch, method='welch')\n",
    "        result['ch' + str(i+1) + '_' + 'pb_delta'] =  pb[0]\n",
    "        result['ch' + str(i+1) + '_' + 'pb_theta'] =  pb[1]\n",
    "        result['ch' + str(i+1) + '_' + 'pb_alpha'] =  pb[2]\n",
    "        result['ch' + str(i+1) + '_' + 'pb_beta'] =  pb[3]\n",
    "        result['ch' + str(i+1) + '_' + 'pb_gamma'] =  pb[4]\n",
    "        result['ch' + str(i+1) + '_' + 'alpha/delta'] =  pb[2]/pb[0]\n",
    "       \n",
    "    \n",
    "    return result      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe1 = eeg_feature(np.array(example))\n",
    "# len(fe1)\n",
    "# 944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG extract\n",
    "####  Complexity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 360, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eegData: 3D np array [chans x ms x epochs] \n",
    "fs = 125\n",
    "eegData = np.array(example).reshape(16,-1,1)\n",
    "eegData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tsalis Entropy (n=1)\n",
    "\n",
    "# alphabet_2 = alphabet_vision[2] \n",
    "# # alphabet_2\n",
    "# # (0, (3064, 3424), 'vision', 'alphabet', 6, 'F')\n",
    "# example_2 = alphabet_list[0].iloc[3786:4206,0:16]\n",
    "# mm = MinMaxScaler()\n",
    "# mm_data = mm.fit_transform(example_2)\n",
    "# eegData_2 = np.array(mm_data).reshape(16,-1,1)\n",
    "\n",
    "# signals need to be normalized, otherwise sometimes there will be an error\n",
    "orders = [1] # list(range(1,10+1))\n",
    "tsalisRes = eeg_et.tsalisEntropy(eegData, bin_min=-200, bin_max=200, binWidth=2,orders=orders)\n",
    "tsalisRes = np.array(tsalisRes)\n",
    "tsalisRes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subband Information Quantity\n",
    "# delta (0.5–4 Hz)\n",
    "eegData_delta = eeg_et.filt_data(eegData, 0.5, 4, fs)\n",
    "ShannonRes_delta = eeg_et.shannonEntropy(eegData_delta, bin_min=-200, bin_max=200, binWidth=2)\n",
    "# theta (4–8 Hz)\n",
    "eegData_theta = eeg_et.filt_data(eegData, 4, 8, fs)\n",
    "ShannonRes_theta = eeg_et.shannonEntropy(eegData_theta, bin_min=-200, bin_max=200, binWidth=2)\n",
    "# alpha (8–13 Hz)\n",
    "eegData_alpha = eeg_et.filt_data(eegData, 8, 13, fs)\n",
    "ShannonRes_alpha = eeg_et.shannonEntropy(eegData_alpha, bin_min=-200, bin_max=200, binWidth=2)\n",
    "# beta (13–30 Hz)\n",
    "eegData_beta = eeg_et.filt_data(eegData, 13, 30, fs)\n",
    "ShannonRes_beta = eeg_et.shannonEntropy(eegData_beta, bin_min=-200, bin_max=200, binWidth=2)\n",
    "# gamma (30–100 Hz), but fs should > 2*high, so we use 60\n",
    "eegData_gamma = eeg_et.filt_data(eegData, 30, 60, fs)\n",
    "ShannonRes_gamma = eeg_et.shannonEntropy(eegData_gamma, bin_min=-200, bin_max=200, binWidth=2)\n",
    "# ShannonRes_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cepstrum Coefficients (n=2)\n",
    "CepstrumRes = eeg_et.mfcc(eegData, fs,order=2)\n",
    "# CepstrumRes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lyapunov Exponent\n",
    "LyapunovRes = eeg_et.lyapunov(eegData)\n",
    "# LyapunovRes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all same 0\n",
    "\n",
    "# False Nearest Neighbor\n",
    "FalseNnRes = eeg_et.falseNearestNeighbor(eegData)\n",
    "FalseNnRes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working\n",
    "# ARMA Coefficients (n=2)\n",
    "# armaRes = eeg_et.arma(eegData,order=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Category Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Frequency\n",
    "medianFreqRes = eeg_et.medianFreq(eegData,fs)\n",
    "# medianFreqRes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Frequency\n",
    "meanFreqRes = eeg_et.meanFreq(eegData,fs)\n",
    "# meanFreqRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot compute because fs < 2*100\n",
    "\n",
    "# # δ band Power\n",
    "# bandPwr_delta = eeg_et.bandPower(eegData, 0.5, 4, fs)\n",
    "# # θ band Power\n",
    "# bandPwr_theta = eeg_et.bandPower(eegData, 4, 8, fs)\n",
    "# # α band Power\n",
    "# bandPwr_alpha = eeg_et.bandPower(eegData, 8, 13, fs)\n",
    "# # β band Power\n",
    "# bandPwr_beta = eeg_et.bandPower(eegData, 13, 30, fs)\n",
    "# # γ band Power\n",
    "# bandPwr_gamma = eeg_et.bandPower(eegData, 30, 60, fs)\n",
    "\n",
    "\n",
    "# α/δ Ratio\n",
    "# ratio_res = eeg_et.eegRatio(eegData,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularity (burst-suppression)\n",
    "regularity_res = eeg_et.eegRegularity(eegData,fs)\n",
    "# regularity_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All are nan, pass\n",
    "\n",
    "# # Voltage < 5μ\n",
    "# volt05_res = eeg_et.eegVoltage(eegData,voltage=5)\n",
    "# # Voltage < 10μ\n",
    "# volt10_res = eeg_et.eegVoltage(eegData,voltage=10)\n",
    "# # Voltage < 20μ\n",
    "# volt20_res = eeg_et.eegVoltage(eegData,voltage=20)\n",
    "\n",
    "\n",
    "# # Burst Band Power for δ\n",
    "# burstBandPwrAlpha = eeg_et.burstBandPowers(eegData, 0.5, 4, fs)\n",
    "# burstBandPwrAlpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all are 0\n",
    "\n",
    "# # Diffuse Slowing\n",
    "# df_res = eeg_et.diffuseSlowing(eegData)\n",
    "# df_res\n",
    "\n",
    "# # Spikes\n",
    "# minNumSamples = int(70*fs/1000)\n",
    "# spikeNum_res = eeg_et.spikeNum(eegData,minNumSamples)\n",
    "# spikeNum_res\n",
    "\n",
    "# # Delta burst after Spike\n",
    "# deltaBurst_res = eeg_et.burstAfterSpike(eegData,eegData_delta,minNumSamples=7,stdAway = 3)\n",
    "# deltaBurst_res\n",
    "\n",
    "# # Sharp spike\n",
    "# sharpSpike_res = eeg_et.shortSpikeNum(eegData,minNumSamples)\n",
    "# sharpSpike_res\n",
    "\n",
    "# # Number of Bursts\n",
    "# numBursts_res = eeg_et.numBursts(eegData,fs)\n",
    "# numBursts_res\n",
    "\n",
    "# # Burst length μ and σ\n",
    "# burstLenMean_res,burstLenStd_res = eeg_et.burstLengthStats(eegData,fs)\n",
    "# burstLenStd_res\n",
    "\n",
    "# # Number of Suppressions\n",
    "# numSupps_res = eeg_et.numSuppressions(eegData,fs)\n",
    "# numSupps_res\n",
    "\n",
    "# # Suppression length μ and σ\n",
    "# suppLenMean_res,suppLenStd_res = eeg_et.suppressionLengthStats(eegData,fs)\n",
    "# suppLenStd_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all same 1, so pass\n",
    "# # Connectivity features- Coherence - δ\n",
    "# coherence_res = eeg_et.coherence(eegData,fs)\n",
    "# coherence_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for EEGExtract.py, the useful features in our case are:\n",
    "\n",
    "Tsalis Entropy, Subband Information Quantity, Cepstrum Coefficients, Lyapunov Exponent, Median Frequency, Regularity (burst-suppression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_feature_2(data, fs=125):\n",
    "    # eegData: 3D np array [chans x ms x epochs] \n",
    "    eegData = np.array(data).reshape(16,-1,1)\n",
    "    result = dict()\n",
    "    \n",
    "    # # signals need to be normalized, otherwise sometimes there will be an error\n",
    "    mm = MinMaxScaler()\n",
    "    mm_data = mm.fit_transform(data)\n",
    "    mm_eegData = np.array(mm_data).reshape(16, -1, 1)\n",
    "    orders = [1]  # list(range(1,10+1))\n",
    "    tsalisRes = eeg_et.tsalisEntropy(mm_eegData, bin_min=-200, bin_max=200, binWidth=2, orders=orders)\n",
    "    tsalisRes = np.array(tsalisRes).reshape(16, )\n",
    "    \n",
    "    for i in range(16):\n",
    "        result['ch' + str(i + 1) + '_' + 'tsalis_entropy'] = tsalisRes[i]\n",
    "        \n",
    "                 \n",
    "    # Subband Information Quantity\n",
    "    eegData_delta = eeg_et.filt_data(eegData, 0.5, 4, fs)\n",
    "    ShannonRes_delta = eeg_et.shannonEntropy(eegData_delta, bin_min=-200, bin_max=200, binWidth=2)\n",
    "    eegData_theta = eeg_et.filt_data(eegData, 4, 8, fs)\n",
    "    ShannonRes_theta = eeg_et.shannonEntropy(eegData_theta, bin_min=-200, bin_max=200, binWidth=2)\n",
    "    eegData_alpha = eeg_et.filt_data(eegData, 8, 13, fs)\n",
    "    ShannonRes_alpha = eeg_et.shannonEntropy(eegData_alpha, bin_min=-200, bin_max=200, binWidth=2)\n",
    "    eegData_beta = eeg_et.filt_data(eegData, 13, 30, fs)\n",
    "    ShannonRes_beta = eeg_et.shannonEntropy(eegData_beta, bin_min=-200, bin_max=200, binWidth=2)\n",
    "    # fs should > 2*high, so we use 60\n",
    "    eegData_gamma = eeg_et.filt_data(eegData, 30, 60, fs)\n",
    "    ShannonRes_gamma = eeg_et.shannonEntropy(eegData_gamma, bin_min=-200, bin_max=200, binWidth=2)\n",
    "\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'PB_SE_1'] =  ShannonRes_delta[i,0]\n",
    "        result['ch' + str(i+1) + '_' + 'PB_SE_2'] =  ShannonRes_theta[i,0]\n",
    "        result['ch' + str(i+1) + '_' + 'PB_SE_3'] =  ShannonRes_alpha[i,0]\n",
    "        result['ch' + str(i+1) + '_' + 'PB_SE_4'] =  ShannonRes_beta[i,0]\n",
    "        result['ch' + str(i+1) + '_' + 'PB_SE_5'] =  ShannonRes_gamma[i,0]\n",
    "        \n",
    "    \n",
    "    # Cepstrum Coefficients (n=2)\n",
    "    CepstrumRes = eeg_et.mfcc(eegData, fs,order=2)\n",
    "    CepstrumRes = np.array(CepstrumRes).reshape(16,2)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'cepstrum_1'] =  CepstrumRes[i,0]\n",
    "        result['ch' + str(i+1) + '_' + 'cepstrum_2'] =  CepstrumRes[i,1]\n",
    "        \n",
    "\n",
    "    # Lyapunov Exponent\n",
    "    LyapunovRes = eeg_et.lyapunov(eegData)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'lyapunov_exponent'] =  LyapunovRes[i,0]\n",
    "        \n",
    "\n",
    "    # Median Frequency\n",
    "    medianFreqRes = eeg_et.medianFreq(eegData,fs)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'median_frequency'] =  medianFreqRes[i,0]\n",
    "    \n",
    "#     # Mean Frequency\n",
    "#     meanFreqRes = eeg_et.meanFreq(eegData,fs)\n",
    "#     for i in range(16):\n",
    "#         result['ch' + str(i+1) + '_' + 'mean_frequency'] =  meanFreqRes[i,0]\n",
    "\n",
    "    # Regularity (burst-suppression)\n",
    "    regularity_res = eeg_et.eegRegularity(eegData,fs)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'regularity'] =  regularity_res[i,0]\n",
    "        \n",
    "    # below, a lot of features are same 0 in example\n",
    "    \n",
    "    # False Nearest Neighbor\n",
    "    FalseNnRes = eeg_et.falseNearestNeighbor(eegData)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'FNN'] =  FalseNnRes[i,0]\n",
    "\n",
    "    # Diffuse Slowing\n",
    "    df_res = eeg_et.diffuseSlowing(eegData)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'diffuse_slowing'] =  df_res[i,0]\n",
    "\n",
    "    # Spikes\n",
    "    minNumSamples = int(70*fs/1000)\n",
    "    spikeNum_res = eeg_et.spikeNum(eegData,minNumSamples)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'spikes'] =  spikeNum_res[i,0]\n",
    "\n",
    "    # # Delta burst after Spike\n",
    "    # deltaBurst_res = eeg_et.burstAfterSpike(eegData,eegData_delta,minNumSamples=7,stdAway = 3)\n",
    "    # deltaBurst_res\n",
    "\n",
    "    # Sharp spike\n",
    "    sharpSpike_res = eeg_et.shortSpikeNum(eegData,minNumSamples)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'sharp_spikes'] = sharpSpike_res[i,0]\n",
    "\n",
    "    # Number of Bursts\n",
    "    numBursts_res = eeg_et.numBursts(eegData,fs)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'num_burst'] = numBursts_res[i,0]\n",
    "\n",
    "    # Burst length μ and σ\n",
    "    burstLenMean_res,burstLenStd_res = eeg_et.burstLengthStats(eegData,fs)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'burst_length_mean'] = burstLenMean_res[i,0]\n",
    "        result['ch' + str(i+1) + '_' + 'burst_length_std'] = burstLenStd_res[i,0]\n",
    "\n",
    "    # Number of Suppressions\n",
    "    numSupps_res = eeg_et.numSuppressions(eegData,fs)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'supressions'] = numSupps_res[i,0]\n",
    "\n",
    "    # Suppression length μ and σ\n",
    "    suppLenMean_res,suppLenStd_res = eeg_et.suppressionLengthStats(eegData,fs)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'supressions_length_mean'] = suppLenMean_res[i,0]\n",
    "        result['ch' + str(i+1) + '_' + 'supressions_length_std'] = suppLenStd_res[i,0]\n",
    "\n",
    "    # all same 1\n",
    "    # Connectivity features- Coherence - δ\n",
    "    coherence_res = eeg_et.coherence(eegData,fs)\n",
    "    for i in range(16):\n",
    "        result['ch' + str(i+1) + '_' + 'coherence'] = coherence_res[i,0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe2 = eeg_feature_2(np.array(example))\n",
    "# len(fe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe_dict = dict(fe1,**fe2)\n",
    "# len(fe_dict.values())\n",
    "# 1296\n",
    "\n",
    "# 1296/16 = 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe_dict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we compare the feature difference, check some 0,1 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabet_2 = alphabet_vision[2] \n",
    "# alphabet_2\n",
    "# # (0, (3064, 3424), 'vision', 'alphabet', 6, 'F')\n",
    "\n",
    "# example_2 = alphabet_list[0].iloc[3786:4206,0:16]\n",
    "# # example_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_dict(data):\n",
    "    fe_1 = eeg_feature(np.array(data))\n",
    "    fe_2 = eeg_feature_2(np.array(data))\n",
    "    feature_dict = dict(fe_1,**fe_2)\n",
    "    \n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(example_2)\n",
    "# 420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fe_dict_2 = generate_feature_dict(np.array(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write all those functions in tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.tools import generate_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe_dict_2 = generate_feature_dict(np.array(example_2))\n",
    "# fe_dict_2['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe_dict_1 = generate_feature_dict(np.array(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing all features to a dataframe and then to the csv files\n",
    "\n",
    "So, at first write features into 4 dataframe, then delete no_change values, same features\n",
    "\n",
    "(those codes would spent a lot of time for excursion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aat_img = dict()\n",
    "\n",
    "count = 0 \n",
    "for item in alphabet_imagination:\n",
    "    current = alphabet_list[item[0]].iloc[item[1][0]:item[1][-1]+1, 0:16]\n",
    "    #print(np.array(current))\n",
    "\n",
    "    current_feature_dict = generate_feature_dict(np.array(current))\n",
    "\n",
    "    \n",
    "    if count == 0:\n",
    "        aat_img['label'] = [item[-1]]\n",
    "        aat_img['label_index'] = [item[-2]]\n",
    "        \n",
    "        for key in current_feature_dict.keys():\n",
    "            aat_img[key] = [current_feature_dict[key]]\n",
    "    else:\n",
    "        aat_img['label'].append(item[-1])\n",
    "        aat_img['label_index'].append(item[-2])\n",
    "        \n",
    "        for key in current_feature_dict.keys():\n",
    "            aat_img[key].append(current_feature_dict[key])\n",
    "    \n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_index</th>\n",
       "      <th>ch1_min</th>\n",
       "      <th>ch1_max</th>\n",
       "      <th>ch1_std</th>\n",
       "      <th>ch1_mean</th>\n",
       "      <th>ch1_coefficient_variation</th>\n",
       "      <th>ch1_mean_abs</th>\n",
       "      <th>ch1_AAC</th>\n",
       "      <th>ch1_CARD</th>\n",
       "      <th>...</th>\n",
       "      <th>ch7_coherence</th>\n",
       "      <th>ch8_coherence</th>\n",
       "      <th>ch9_coherence</th>\n",
       "      <th>ch10_coherence</th>\n",
       "      <th>ch11_coherence</th>\n",
       "      <th>ch12_coherence</th>\n",
       "      <th>ch13_coherence</th>\n",
       "      <th>ch14_coherence</th>\n",
       "      <th>ch15_coherence</th>\n",
       "      <th>ch16_coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>9</td>\n",
       "      <td>-3464.721556</td>\n",
       "      <td>-3318.384685</td>\n",
       "      <td>34.719767</td>\n",
       "      <td>-3372.674790</td>\n",
       "      <td>-0.010294</td>\n",
       "      <td>3372.674790</td>\n",
       "      <td>7.005015</td>\n",
       "      <td>403.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.732249</td>\n",
       "      <td>0.464366</td>\n",
       "      <td>0.634774</td>\n",
       "      <td>0.689424</td>\n",
       "      <td>0.396397</td>\n",
       "      <td>0.636329</td>\n",
       "      <td>0.598004</td>\n",
       "      <td>0.574852</td>\n",
       "      <td>0.625444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>-3497.288048</td>\n",
       "      <td>-3331.281642</td>\n",
       "      <td>45.765203</td>\n",
       "      <td>-3394.721899</td>\n",
       "      <td>-0.013481</td>\n",
       "      <td>3394.721899</td>\n",
       "      <td>6.749174</td>\n",
       "      <td>351.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q</td>\n",
       "      <td>17</td>\n",
       "      <td>-3790.073549</td>\n",
       "      <td>-3653.392631</td>\n",
       "      <td>30.437155</td>\n",
       "      <td>-3703.890051</td>\n",
       "      <td>-0.008218</td>\n",
       "      <td>3703.890051</td>\n",
       "      <td>6.333221</td>\n",
       "      <td>348.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>-3810.950078</td>\n",
       "      <td>-3683.321617</td>\n",
       "      <td>35.116086</td>\n",
       "      <td>-3737.206895</td>\n",
       "      <td>-0.009396</td>\n",
       "      <td>3737.206895</td>\n",
       "      <td>6.486997</td>\n",
       "      <td>404.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558202</td>\n",
       "      <td>0.591124</td>\n",
       "      <td>0.658237</td>\n",
       "      <td>0.595267</td>\n",
       "      <td>0.661488</td>\n",
       "      <td>0.575933</td>\n",
       "      <td>0.565323</td>\n",
       "      <td>0.714385</td>\n",
       "      <td>0.763491</td>\n",
       "      <td>0.846974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V</td>\n",
       "      <td>22</td>\n",
       "      <td>-3902.100492</td>\n",
       "      <td>-3756.836505</td>\n",
       "      <td>36.499483</td>\n",
       "      <td>-3811.941937</td>\n",
       "      <td>-0.009575</td>\n",
       "      <td>3811.941937</td>\n",
       "      <td>6.292202</td>\n",
       "      <td>345.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_index      ch1_min      ch1_max    ch1_std     ch1_mean  \\\n",
       "0     I            9 -3464.721556 -3318.384685  34.719767 -3372.674790   \n",
       "1     F            6 -3497.288048 -3331.281642  45.765203 -3394.721899   \n",
       "2     Q           17 -3790.073549 -3653.392631  30.437155 -3703.890051   \n",
       "3     D            4 -3810.950078 -3683.321617  35.116086 -3737.206895   \n",
       "4     V           22 -3902.100492 -3756.836505  36.499483 -3811.941937   \n",
       "\n",
       "   ch1_coefficient_variation  ch1_mean_abs   ch1_AAC  ch1_CARD  ...  \\\n",
       "0                  -0.010294   3372.674790  7.005015     403.0  ...   \n",
       "1                  -0.013481   3394.721899  6.749174     351.0  ...   \n",
       "2                  -0.008218   3703.890051  6.333221     348.0  ...   \n",
       "3                  -0.009396   3737.206895  6.486997     404.0  ...   \n",
       "4                  -0.009575   3811.941937  6.292202     345.0  ...   \n",
       "\n",
       "   ch7_coherence  ch8_coherence  ch9_coherence  ch10_coherence  \\\n",
       "0       0.474576       0.732249       0.464366        0.634774   \n",
       "1       1.000000       1.000000       1.000000        1.000000   \n",
       "2       1.000000       1.000000       1.000000        1.000000   \n",
       "3       0.558202       0.591124       0.658237        0.595267   \n",
       "4       1.000000       1.000000       1.000000        1.000000   \n",
       "\n",
       "   ch11_coherence  ch12_coherence  ch13_coherence  ch14_coherence  \\\n",
       "0        0.689424        0.396397        0.636329        0.598004   \n",
       "1        1.000000        1.000000        1.000000        1.000000   \n",
       "2        1.000000        1.000000        1.000000        1.000000   \n",
       "3        0.661488        0.575933        0.565323        0.714385   \n",
       "4        1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "   ch15_coherence  ch16_coherence  \n",
       "0        0.574852        0.625444  \n",
       "1        1.000000        1.000000  \n",
       "2        1.000000        1.000000  \n",
       "3        0.763491        0.846974  \n",
       "4        1.000000        1.000000  \n",
       "\n",
       "[5 rows x 1298 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aat_img = pd.DataFrame(aat_img)\n",
    "aat_img.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 832 entries, 0 to 831\n",
      "Columns: 1298 entries, label to ch16_coherence\n",
      "dtypes: float64(1280), int32(16), int64(1), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "aat_img.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "aat_vision = dict()\n",
    "\n",
    "count = 0 \n",
    "for item in alphabet_vision:\n",
    "    current = alphabet_list[item[0]].iloc[item[1][0]:item[1][-1]+1, 0:16]\n",
    "    #print(np.array(current))\n",
    "\n",
    "    current_feature_dict = generate_feature_dict(np.array(current))\n",
    "\n",
    "    \n",
    "    if count == 0:\n",
    "        aat_vision['label'] = [item[-1]]\n",
    "        aat_vision['label_index'] = [item[-2]]\n",
    "        \n",
    "        for key in current_feature_dict.keys():\n",
    "            aat_vision[key] = [current_feature_dict[key]]\n",
    "    else:\n",
    "        aat_vision['label'].append(item[-1])\n",
    "        aat_vision['label_index'].append(item[-2])\n",
    "        \n",
    "        for key in current_feature_dict.keys():\n",
    "            aat_vision[key].append(current_feature_dict[key])\n",
    "    \n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_index</th>\n",
       "      <th>ch1_min</th>\n",
       "      <th>ch1_max</th>\n",
       "      <th>ch1_std</th>\n",
       "      <th>ch1_mean</th>\n",
       "      <th>ch1_coefficient_variation</th>\n",
       "      <th>ch1_mean_abs</th>\n",
       "      <th>ch1_AAC</th>\n",
       "      <th>ch1_CARD</th>\n",
       "      <th>...</th>\n",
       "      <th>ch7_coherence</th>\n",
       "      <th>ch8_coherence</th>\n",
       "      <th>ch9_coherence</th>\n",
       "      <th>ch10_coherence</th>\n",
       "      <th>ch11_coherence</th>\n",
       "      <th>ch12_coherence</th>\n",
       "      <th>ch13_coherence</th>\n",
       "      <th>ch14_coherence</th>\n",
       "      <th>ch15_coherence</th>\n",
       "      <th>ch16_coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>9</td>\n",
       "      <td>-3411.345591</td>\n",
       "      <td>-3262.952359</td>\n",
       "      <td>31.367440</td>\n",
       "      <td>-3313.606131</td>\n",
       "      <td>-0.009466</td>\n",
       "      <td>3313.606131</td>\n",
       "      <td>6.992184</td>\n",
       "      <td>342.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>-3454.283292</td>\n",
       "      <td>-3334.187369</td>\n",
       "      <td>22.167027</td>\n",
       "      <td>-3374.728294</td>\n",
       "      <td>-0.006569</td>\n",
       "      <td>3374.728294</td>\n",
       "      <td>6.986747</td>\n",
       "      <td>332.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q</td>\n",
       "      <td>17</td>\n",
       "      <td>-3772.192153</td>\n",
       "      <td>-3341.965776</td>\n",
       "      <td>75.384702</td>\n",
       "      <td>-3591.181606</td>\n",
       "      <td>-0.020992</td>\n",
       "      <td>3591.181606</td>\n",
       "      <td>6.906636</td>\n",
       "      <td>413.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508136</td>\n",
       "      <td>0.509386</td>\n",
       "      <td>0.660148</td>\n",
       "      <td>0.678768</td>\n",
       "      <td>0.437121</td>\n",
       "      <td>0.62361</td>\n",
       "      <td>0.630649</td>\n",
       "      <td>0.591844</td>\n",
       "      <td>0.544863</td>\n",
       "      <td>0.530359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>-3786.139642</td>\n",
       "      <td>-3662.221570</td>\n",
       "      <td>21.228800</td>\n",
       "      <td>-3707.487320</td>\n",
       "      <td>-0.005726</td>\n",
       "      <td>3707.487320</td>\n",
       "      <td>6.090696</td>\n",
       "      <td>334.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V</td>\n",
       "      <td>22</td>\n",
       "      <td>-3847.428125</td>\n",
       "      <td>-3682.516954</td>\n",
       "      <td>32.712980</td>\n",
       "      <td>-3751.086843</td>\n",
       "      <td>-0.008721</td>\n",
       "      <td>3751.086843</td>\n",
       "      <td>6.442441</td>\n",
       "      <td>347.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_index      ch1_min      ch1_max    ch1_std     ch1_mean  \\\n",
       "0     I            9 -3411.345591 -3262.952359  31.367440 -3313.606131   \n",
       "1     F            6 -3454.283292 -3334.187369  22.167027 -3374.728294   \n",
       "2     Q           17 -3772.192153 -3341.965776  75.384702 -3591.181606   \n",
       "3     D            4 -3786.139642 -3662.221570  21.228800 -3707.487320   \n",
       "4     V           22 -3847.428125 -3682.516954  32.712980 -3751.086843   \n",
       "\n",
       "   ch1_coefficient_variation  ch1_mean_abs   ch1_AAC  ch1_CARD  ...  \\\n",
       "0                  -0.009466   3313.606131  6.992184     342.0  ...   \n",
       "1                  -0.006569   3374.728294  6.986747     332.0  ...   \n",
       "2                  -0.020992   3591.181606  6.906636     413.0  ...   \n",
       "3                  -0.005726   3707.487320  6.090696     334.0  ...   \n",
       "4                  -0.008721   3751.086843  6.442441     347.0  ...   \n",
       "\n",
       "   ch7_coherence  ch8_coherence  ch9_coherence  ch10_coherence  \\\n",
       "0       1.000000       1.000000       1.000000        1.000000   \n",
       "1       1.000000       1.000000       1.000000        1.000000   \n",
       "2       0.508136       0.509386       0.660148        0.678768   \n",
       "3       1.000000       1.000000       1.000000        1.000000   \n",
       "4       1.000000       1.000000       1.000000        1.000000   \n",
       "\n",
       "   ch11_coherence  ch12_coherence  ch13_coherence  ch14_coherence  \\\n",
       "0        1.000000         1.00000        1.000000        1.000000   \n",
       "1        1.000000         1.00000        1.000000        1.000000   \n",
       "2        0.437121         0.62361        0.630649        0.591844   \n",
       "3        1.000000         1.00000        1.000000        1.000000   \n",
       "4        1.000000         1.00000        1.000000        1.000000   \n",
       "\n",
       "   ch15_coherence  ch16_coherence  \n",
       "0        1.000000        1.000000  \n",
       "1        1.000000        1.000000  \n",
       "2        0.544863        0.530359  \n",
       "3        1.000000        1.000000  \n",
       "4        1.000000        1.000000  \n",
       "\n",
       "[5 rows x 1298 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aat_vision = pd.DataFrame(aat_vision)\n",
    "aat_vision.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 832 entries, 0 to 831\n",
      "Columns: 1298 entries, label to ch16_coherence\n",
      "dtypes: float64(1280), int32(16), int64(1), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "aat_vision.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "asl_vision_dict = dict()\n",
    "\n",
    "count = 0 \n",
    "for item in asl_vision:\n",
    "    current = asl_list[item[0]].iloc[item[1][0]:item[1][-1]+1, 0:16]\n",
    "    #print(np.array(current))\n",
    "\n",
    "    current_feature_dict = generate_feature_dict(np.array(current))\n",
    "\n",
    "    \n",
    "    if count == 0:\n",
    "        asl_vision_dict['label'] = [item[-1]]\n",
    "        asl_vision_dict['label_index'] = [item[-2]]\n",
    "        \n",
    "        for key in current_feature_dict.keys():\n",
    "            asl_vision_dict[key] = [current_feature_dict[key]]\n",
    "    else:\n",
    "        asl_vision_dict['label'].append(item[-1])\n",
    "        asl_vision_dict['label_index'].append(item[-2])\n",
    "        \n",
    "        for key in current_feature_dict.keys():\n",
    "            asl_vision_dict[key].append(current_feature_dict[key])\n",
    "    \n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_index</th>\n",
       "      <th>ch1_min</th>\n",
       "      <th>ch1_max</th>\n",
       "      <th>ch1_std</th>\n",
       "      <th>ch1_mean</th>\n",
       "      <th>ch1_coefficient_variation</th>\n",
       "      <th>ch1_mean_abs</th>\n",
       "      <th>ch1_AAC</th>\n",
       "      <th>ch1_CARD</th>\n",
       "      <th>...</th>\n",
       "      <th>ch7_coherence</th>\n",
       "      <th>ch8_coherence</th>\n",
       "      <th>ch9_coherence</th>\n",
       "      <th>ch10_coherence</th>\n",
       "      <th>ch11_coherence</th>\n",
       "      <th>ch12_coherence</th>\n",
       "      <th>ch13_coherence</th>\n",
       "      <th>ch14_coherence</th>\n",
       "      <th>ch15_coherence</th>\n",
       "      <th>ch16_coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>9</td>\n",
       "      <td>-4050.292558</td>\n",
       "      <td>-3866.404756</td>\n",
       "      <td>33.093499</td>\n",
       "      <td>-3930.450824</td>\n",
       "      <td>-0.008420</td>\n",
       "      <td>3930.450824</td>\n",
       "      <td>7.109159</td>\n",
       "      <td>338.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>-4186.369978</td>\n",
       "      <td>-3973.626074</td>\n",
       "      <td>50.269552</td>\n",
       "      <td>-4030.724379</td>\n",
       "      <td>-0.012472</td>\n",
       "      <td>4030.724379</td>\n",
       "      <td>6.776665</td>\n",
       "      <td>341.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q</td>\n",
       "      <td>17</td>\n",
       "      <td>-4136.704402</td>\n",
       "      <td>-4000.872851</td>\n",
       "      <td>22.363986</td>\n",
       "      <td>-4041.348081</td>\n",
       "      <td>-0.005534</td>\n",
       "      <td>4041.348081</td>\n",
       "      <td>6.710153</td>\n",
       "      <td>379.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578976</td>\n",
       "      <td>0.640656</td>\n",
       "      <td>0.603461</td>\n",
       "      <td>0.419225</td>\n",
       "      <td>0.583453</td>\n",
       "      <td>0.739717</td>\n",
       "      <td>0.623981</td>\n",
       "      <td>0.684624</td>\n",
       "      <td>0.549145</td>\n",
       "      <td>0.583670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>-4237.041382</td>\n",
       "      <td>-4044.458752</td>\n",
       "      <td>38.720702</td>\n",
       "      <td>-4094.307705</td>\n",
       "      <td>-0.009457</td>\n",
       "      <td>4094.307705</td>\n",
       "      <td>7.362214</td>\n",
       "      <td>347.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587184</td>\n",
       "      <td>0.467851</td>\n",
       "      <td>0.670944</td>\n",
       "      <td>0.598360</td>\n",
       "      <td>0.592328</td>\n",
       "      <td>0.687602</td>\n",
       "      <td>0.701118</td>\n",
       "      <td>0.538246</td>\n",
       "      <td>0.658707</td>\n",
       "      <td>0.529035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V</td>\n",
       "      <td>22</td>\n",
       "      <td>-4209.951068</td>\n",
       "      <td>-4103.601468</td>\n",
       "      <td>19.130984</td>\n",
       "      <td>-4128.230552</td>\n",
       "      <td>-0.004634</td>\n",
       "      <td>4128.230552</td>\n",
       "      <td>7.226734</td>\n",
       "      <td>319.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_index      ch1_min      ch1_max    ch1_std     ch1_mean  \\\n",
       "0     I            9 -4050.292558 -3866.404756  33.093499 -3930.450824   \n",
       "1     F            6 -4186.369978 -3973.626074  50.269552 -4030.724379   \n",
       "2     Q           17 -4136.704402 -4000.872851  22.363986 -4041.348081   \n",
       "3     D            4 -4237.041382 -4044.458752  38.720702 -4094.307705   \n",
       "4     V           22 -4209.951068 -4103.601468  19.130984 -4128.230552   \n",
       "\n",
       "   ch1_coefficient_variation  ch1_mean_abs   ch1_AAC  ch1_CARD  ...  \\\n",
       "0                  -0.008420   3930.450824  7.109159     338.0  ...   \n",
       "1                  -0.012472   4030.724379  6.776665     341.0  ...   \n",
       "2                  -0.005534   4041.348081  6.710153     379.0  ...   \n",
       "3                  -0.009457   4094.307705  7.362214     347.0  ...   \n",
       "4                  -0.004634   4128.230552  7.226734     319.0  ...   \n",
       "\n",
       "   ch7_coherence  ch8_coherence  ch9_coherence  ch10_coherence  \\\n",
       "0       1.000000       1.000000       1.000000        1.000000   \n",
       "1       1.000000       1.000000       1.000000        1.000000   \n",
       "2       0.578976       0.640656       0.603461        0.419225   \n",
       "3       0.587184       0.467851       0.670944        0.598360   \n",
       "4       1.000000       1.000000       1.000000        1.000000   \n",
       "\n",
       "   ch11_coherence  ch12_coherence  ch13_coherence  ch14_coherence  \\\n",
       "0        1.000000        1.000000        1.000000        1.000000   \n",
       "1        1.000000        1.000000        1.000000        1.000000   \n",
       "2        0.583453        0.739717        0.623981        0.684624   \n",
       "3        0.592328        0.687602        0.701118        0.538246   \n",
       "4        1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "   ch15_coherence  ch16_coherence  \n",
       "0        1.000000        1.000000  \n",
       "1        1.000000        1.000000  \n",
       "2        0.549145        0.583670  \n",
       "3        0.658707        0.529035  \n",
       "4        1.000000        1.000000  \n",
       "\n",
       "[5 rows x 1298 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asl_vision_dict = pd.DataFrame(asl_vision_dict)\n",
    "asl_vision_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 832 entries, 0 to 831\n",
      "Columns: 1298 entries, label to ch16_coherence\n",
      "dtypes: float64(1280), int32(16), int64(1), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "asl_vision_dict.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "asl_img = dict()\n",
    "\n",
    "count = 0 \n",
    "for item in asl_imagination:\n",
    "    current = asl_list[item[0]].iloc[item[1][0]:item[1][-1]+1, 0:16]\n",
    "    #print(np.array(current))\n",
    "\n",
    "    current_feature_dict = generate_feature_dict(np.array(current))\n",
    "\n",
    "    \n",
    "    if count == 0:\n",
    "        asl_img ['label'] = [item[-1]]\n",
    "        asl_img ['label_index'] = [item[-2]]\n",
    "        \n",
    "        for key in current_feature_dict.keys():\n",
    "            asl_img [key] = [current_feature_dict[key]]\n",
    "    else:\n",
    "        asl_img['label'].append(item[-1])\n",
    "        asl_img['label_index'].append(item[-2])\n",
    "        \n",
    "        for key in current_feature_dict.keys():\n",
    "            asl_img[key].append(current_feature_dict[key])\n",
    "    \n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_index</th>\n",
       "      <th>ch1_min</th>\n",
       "      <th>ch1_max</th>\n",
       "      <th>ch1_std</th>\n",
       "      <th>ch1_mean</th>\n",
       "      <th>ch1_coefficient_variation</th>\n",
       "      <th>ch1_mean_abs</th>\n",
       "      <th>ch1_AAC</th>\n",
       "      <th>ch1_CARD</th>\n",
       "      <th>...</th>\n",
       "      <th>ch7_coherence</th>\n",
       "      <th>ch8_coherence</th>\n",
       "      <th>ch9_coherence</th>\n",
       "      <th>ch10_coherence</th>\n",
       "      <th>ch11_coherence</th>\n",
       "      <th>ch12_coherence</th>\n",
       "      <th>ch13_coherence</th>\n",
       "      <th>ch14_coherence</th>\n",
       "      <th>ch15_coherence</th>\n",
       "      <th>ch16_coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>9</td>\n",
       "      <td>-4115.336134</td>\n",
       "      <td>-3938.153856</td>\n",
       "      <td>34.241139</td>\n",
       "      <td>-3986.794278</td>\n",
       "      <td>-0.008589</td>\n",
       "      <td>3986.794278</td>\n",
       "      <td>7.532803</td>\n",
       "      <td>399.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635704</td>\n",
       "      <td>0.517993</td>\n",
       "      <td>0.671713</td>\n",
       "      <td>0.711160</td>\n",
       "      <td>0.496245</td>\n",
       "      <td>0.473008</td>\n",
       "      <td>0.577944</td>\n",
       "      <td>0.592671</td>\n",
       "      <td>0.533941</td>\n",
       "      <td>0.631285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>-4174.545905</td>\n",
       "      <td>-4041.128342</td>\n",
       "      <td>25.232193</td>\n",
       "      <td>-4073.135793</td>\n",
       "      <td>-0.006195</td>\n",
       "      <td>4073.135793</td>\n",
       "      <td>6.991390</td>\n",
       "      <td>325.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q</td>\n",
       "      <td>17</td>\n",
       "      <td>-4168.779155</td>\n",
       "      <td>-4019.894185</td>\n",
       "      <td>33.204783</td>\n",
       "      <td>-4071.318429</td>\n",
       "      <td>-0.008156</td>\n",
       "      <td>4071.318429</td>\n",
       "      <td>7.110579</td>\n",
       "      <td>333.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>-4201.233888</td>\n",
       "      <td>-4049.264377</td>\n",
       "      <td>29.108179</td>\n",
       "      <td>-4095.197891</td>\n",
       "      <td>-0.007108</td>\n",
       "      <td>4095.197891</td>\n",
       "      <td>7.200657</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.706395</td>\n",
       "      <td>0.817993</td>\n",
       "      <td>0.689147</td>\n",
       "      <td>0.795852</td>\n",
       "      <td>0.837017</td>\n",
       "      <td>0.669407</td>\n",
       "      <td>0.595486</td>\n",
       "      <td>0.610734</td>\n",
       "      <td>0.686829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V</td>\n",
       "      <td>22</td>\n",
       "      <td>-4294.060683</td>\n",
       "      <td>-4121.885195</td>\n",
       "      <td>35.754917</td>\n",
       "      <td>-4186.625657</td>\n",
       "      <td>-0.008540</td>\n",
       "      <td>4186.625657</td>\n",
       "      <td>7.370053</td>\n",
       "      <td>345.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_index      ch1_min      ch1_max    ch1_std     ch1_mean  \\\n",
       "0     I            9 -4115.336134 -3938.153856  34.241139 -3986.794278   \n",
       "1     F            6 -4174.545905 -4041.128342  25.232193 -4073.135793   \n",
       "2     Q           17 -4168.779155 -4019.894185  33.204783 -4071.318429   \n",
       "3     D            4 -4201.233888 -4049.264377  29.108179 -4095.197891   \n",
       "4     V           22 -4294.060683 -4121.885195  35.754917 -4186.625657   \n",
       "\n",
       "   ch1_coefficient_variation  ch1_mean_abs   ch1_AAC  ch1_CARD  ...  \\\n",
       "0                  -0.008589   3986.794278  7.532803     399.0  ...   \n",
       "1                  -0.006195   4073.135793  6.991390     325.0  ...   \n",
       "2                  -0.008156   4071.318429  7.110579     333.0  ...   \n",
       "3                  -0.007108   4095.197891  7.200657     371.0  ...   \n",
       "4                  -0.008540   4186.625657  7.370053     345.0  ...   \n",
       "\n",
       "   ch7_coherence  ch8_coherence  ch9_coherence  ch10_coherence  \\\n",
       "0       0.635704       0.517993       0.671713        0.711160   \n",
       "1       1.000000       1.000000       1.000000        1.000000   \n",
       "2       1.000000       1.000000       1.000000        1.000000   \n",
       "3       0.768519       0.706395       0.817993        0.689147   \n",
       "4       1.000000       1.000000       1.000000        1.000000   \n",
       "\n",
       "   ch11_coherence  ch12_coherence  ch13_coherence  ch14_coherence  \\\n",
       "0        0.496245        0.473008        0.577944        0.592671   \n",
       "1        1.000000        1.000000        1.000000        1.000000   \n",
       "2        1.000000        1.000000        1.000000        1.000000   \n",
       "3        0.795852        0.837017        0.669407        0.595486   \n",
       "4        1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "   ch15_coherence  ch16_coherence  \n",
       "0        0.533941        0.631285  \n",
       "1        1.000000        1.000000  \n",
       "2        1.000000        1.000000  \n",
       "3        0.610734        0.686829  \n",
       "4        1.000000        1.000000  \n",
       "\n",
       "[5 rows x 1298 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asl_img = pd.DataFrame(asl_img)\n",
    "asl_img.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete no_changing features and store 4 DF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our 4 DF, delete useless lines and store them in csv files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_aat_img = list()\n",
    "for i in aat_img.columns:\n",
    "    current = aat_img[i]\n",
    "    \n",
    "    current = current.tolist()\n",
    "    # delete duplicated values in the list\n",
    "    b=len(set(current))\n",
    "    if b==1:\n",
    "        # print(b)\n",
    "        b1_aat_img.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_aat_vision = list()\n",
    "for i in aat_vision.columns:\n",
    "    current = aat_vision[i]\n",
    "    \n",
    "    current = current.tolist()\n",
    "    b=len(set(current))\n",
    "    if b==1:\n",
    "        # print(b)\n",
    "        b1_aat_vision.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_asl_img = list()\n",
    "for i in asl_img.columns:\n",
    "    current = asl_img[i]\n",
    "    \n",
    "    current = current.tolist()\n",
    "    b=len(set(current))\n",
    "    if b==1:\n",
    "        # print(b)\n",
    "        b1_asl_img.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_asl_vision = list()\n",
    "for i in asl_vision_dict.columns:\n",
    "    current = asl_vision_dict[i]\n",
    "    \n",
    "    current = current.tolist()\n",
    "    b=len(set(current))\n",
    "    if b==1:\n",
    "        # print(b)\n",
    "        b1_asl_vision.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the intersection of four sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 168 168 164 167\n"
     ]
    }
   ],
   "source": [
    "r = list(set(b1_aat_img).intersection(b1_aat_vision, b1_asl_img, b1_asl_vision)) \n",
    "print(len(r), len(b1_aat_img), len(b1_aat_vision), len(b1_asl_img), len(b1_asl_vision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in asl_vision_dict.columns:\n",
    "#     if 'cepstrum_2' in i:\n",
    "#         print('oui')\n",
    "#     if 'mean_frequency' in i:\n",
    "#         print('oui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ch16_spikes', 'ch10_diffuse_slowing', 'ch13_diffuse_slowing', 'ch1_sharp_spikes', 'ch6_num_burst', 'ch11_supressions_length_std', 'ch5_supressions_length_std', 'ch2_spikes', 'ch8_supressions_length_mean', 'ch1_FNN', 'ch16_supressions', 'ch9_FNN', 'ch10_num_burst', 'ch3_sharp_spikes', 'ch6_supressions_length_std', 'ch15_num_burst', 'ch4_supressions_length_std', 'ch13_burst_length_mean', 'ch6_supressions', 'ch5_sharp_spikes', 'ch16_supressions_length_std', 'ch14_num_burst', 'ch14_diffuse_slowing', 'ch4_burst_length_std', 'ch13_spikes', 'ch16_FNN', 'ch7_spikes', 'ch7_num_zero_crossing', 'ch1_num_burst', 'ch9_spikes', 'ch5_FNN', 'ch10_supressions_length_mean', 'ch6_sharp_spikes', 'ch10_supressions_length_std', 'ch16_burst_length_mean', 'ch15_FNN', 'ch8_burst_length_mean', 'ch11_burst_length_std', 'ch1_diffuse_slowing', 'ch11_sharp_spikes', 'ch12_diffuse_slowing', 'ch9_burst_length_mean', 'ch10_burst_length_std', 'ch14_sharp_spikes', 'ch2_burst_length_std', 'ch11_supressions_length_mean', 'ch4_supressions_length_mean', 'ch12_supressions', 'ch13_supressions_length_std', 'ch5_supressions', 'ch8_diffuse_slowing', 'ch12_supressions_length_mean', 'ch15_sharp_spikes', 'ch4_sharp_spikes', 'ch6_FNN', 'ch9_supressions_length_std', 'ch14_supressions_length_mean', 'ch13_supressions', 'ch2_FNN', 'ch1_spikes', 'ch12_burst_length_mean', 'ch5_supressions_length_mean', 'ch6_supressions_length_mean', 'ch7_diffuse_slowing', 'ch14_FNN', 'ch11_supressions', 'ch12_sharp_spikes', 'ch7_burst_length_std', 'ch8_FNN', 'ch8_spikes', 'ch4_spikes', 'ch6_num_zero_crossing', 'ch7_supressions_length_mean', 'ch3_num_burst', 'ch2_supressions_length_mean', 'ch3_supressions_length_std', 'ch7_FNN', 'ch1_supressions_length_mean', 'ch15_burst_length_mean', 'ch7_supressions', 'ch16_burst_length_std', 'ch2_diffuse_slowing', 'ch14_supressions', 'ch2_supressions_length_std', 'ch12_spikes', 'ch10_spikes', 'ch15_supressions_length_std', 'ch10_supressions', 'ch11_FNN', 'ch11_num_burst', 'ch11_spikes', 'ch3_FNN', 'ch4_diffuse_slowing', 'ch7_burst_length_mean', 'ch5_burst_length_mean', 'ch6_diffuse_slowing', 'ch14_burst_length_mean', 'ch15_diffuse_slowing', 'ch7_supressions_length_std', 'ch14_supressions_length_std', 'ch15_burst_length_std', 'ch13_supressions_length_mean', 'ch2_supressions', 'ch8_supressions_length_std', 'ch3_supressions', 'ch2_sharp_spikes', 'ch5_spikes', 'ch13_burst_length_std', 'ch15_supressions', 'ch13_num_burst', 'ch3_supressions_length_mean', 'ch7_sharp_spikes', 'ch16_diffuse_slowing', 'ch16_sharp_spikes', 'ch1_supressions_length_std', 'ch8_sharp_spikes', 'ch3_diffuse_slowing', 'ch15_supressions_length_mean', 'ch13_FNN', 'ch9_diffuse_slowing', 'ch5_burst_length_std', 'ch9_supressions', 'ch1_burst_length_std', 'ch3_burst_length_std', 'ch16_num_burst', 'ch9_sharp_spikes', 'ch10_FNN', 'ch4_FNN', 'ch3_burst_length_mean', 'ch6_burst_length_mean', 'ch15_spikes', 'ch14_burst_length_std', 'ch2_burst_length_mean', 'ch6_burst_length_std', 'ch14_spikes', 'ch4_num_burst', 'ch11_burst_length_mean', 'ch8_num_burst', 'ch2_num_burst', 'ch16_supressions_length_mean', 'ch8_supressions', 'ch7_num_burst', 'ch3_spikes', 'ch8_burst_length_std', 'ch4_burst_length_mean', 'ch12_burst_length_std', 'ch12_supressions_length_std', 'ch12_num_burst', 'ch5_num_burst', 'ch9_num_burst', 'ch5_diffuse_slowing', 'ch10_burst_length_mean', 'ch13_sharp_spikes', 'ch4_supressions', 'ch1_burst_length_mean', 'ch9_burst_length_std', 'ch12_FNN', 'ch11_diffuse_slowing', 'ch10_sharp_spikes', 'ch6_spikes', 'ch1_supressions', 'ch9_supressions_length_mean']\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "unuse_feature_list = list()\n",
    "for item in r:\n",
    "    \n",
    "    strr = item.replace(\"ch1_\",'').replace(\"ch2_\",'').replace(\"ch3_\",'').replace(\"ch4_\",'').replace(\"ch5_\",'').replace(\"ch6_\",'')\n",
    "    strr = strr.replace(\"ch7_\",'').replace(\"ch8_\",'').replace(\"ch9_\",'').replace(\"ch10_\",'').replace(\"ch11_\",'').replace(\"ch12_\",'')\n",
    "    strr = strr.replace(\"ch13_\",'').replace(\"ch14_\",'').replace(\"ch15_\",'').replace(\"ch16_\",'')\n",
    "    \n",
    "    unuse_feature_list.append(strr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FNN',\n",
       " 'burst_length_mean',\n",
       " 'burst_length_std',\n",
       " 'diffuse_slowing',\n",
       " 'num_burst',\n",
       " 'num_zero_crossing',\n",
       " 'sharp_spikes',\n",
       " 'spikes',\n",
       " 'supressions',\n",
       " 'supressions_length_mean',\n",
       " 'supressions_length_std'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(unuse_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(unuse_feature_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we could find those features are not useful in our case, so we will delete 11*16=176 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check b=2 and b=3 features distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_aat_img = list()\n",
    "for i in aat_img.columns:\n",
    "    current = aat_img[i]\n",
    "    \n",
    "    current = current.tolist()\n",
    "    # delete duplicated values in the list\n",
    "    b=len(set(current))\n",
    "    if b==2:\n",
    "        # print(b)\n",
    "        b2_aat_img.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ch3_num_zero_crossing']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_aat_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 831, 27: 1})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# one example\n",
    "Counter(aat_img[b2_aat_img[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 830, 38: 1, 145: 1})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b3_aat_img = list()\n",
    "for i in aat_img.columns:\n",
    "    current = aat_img[i]\n",
    "    \n",
    "    current = current.tolist()\n",
    "    # delete duplicated values in the list\n",
    "    b=len(set(current))\n",
    "    if b==3:\n",
    "        # print(b)\n",
    "        b3_aat_img.append(i)\n",
    "Counter(aat_img[b3_aat_img[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ch11_num_zero_crossing', 'ch13_num_zero_crossing']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 831, 1: 1})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_aat_vision = list()\n",
    "for i in aat_vision.columns:\n",
    "    current = aat_vision[i]\n",
    "    \n",
    "    current = current.tolist()\n",
    "    b=len(set(current))\n",
    "    if b==2:\n",
    "        # print(b)\n",
    "        b2_aat_vision.append(i)\n",
    "print(b2_aat_vision)\n",
    "Counter(aat_vision[b2_aat_vision[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop there and delete 176 features then store DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_index = list()\n",
    "ch_prefix = ['ch'+str(i+1)+\"_\" for i in range(16)]\n",
    "\n",
    "for item in set(unuse_feature_list):\n",
    "    for j in ch_prefix:\n",
    "        delete_index.append(j+item)\n",
    "\n",
    "        \n",
    "len(delete_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = aat_img.copy().drop(labels=delete_index, axis=1)\n",
    "df2 = aat_vision.copy().drop(labels=delete_index, axis=1)\n",
    "df3 = asl_img.copy().drop(labels=delete_index, axis=1)\n",
    "df4 = asl_vision_dict.copy().drop(labels=delete_index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_index</th>\n",
       "      <th>ch1_min</th>\n",
       "      <th>ch1_max</th>\n",
       "      <th>ch1_std</th>\n",
       "      <th>ch1_mean</th>\n",
       "      <th>ch1_coefficient_variation</th>\n",
       "      <th>ch1_mean_abs</th>\n",
       "      <th>ch1_AAC</th>\n",
       "      <th>ch1_CARD</th>\n",
       "      <th>...</th>\n",
       "      <th>ch7_coherence</th>\n",
       "      <th>ch8_coherence</th>\n",
       "      <th>ch9_coherence</th>\n",
       "      <th>ch10_coherence</th>\n",
       "      <th>ch11_coherence</th>\n",
       "      <th>ch12_coherence</th>\n",
       "      <th>ch13_coherence</th>\n",
       "      <th>ch14_coherence</th>\n",
       "      <th>ch15_coherence</th>\n",
       "      <th>ch16_coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>9</td>\n",
       "      <td>-3464.721556</td>\n",
       "      <td>-3318.384685</td>\n",
       "      <td>34.719767</td>\n",
       "      <td>-3372.674790</td>\n",
       "      <td>-0.010294</td>\n",
       "      <td>3372.674790</td>\n",
       "      <td>7.005015</td>\n",
       "      <td>403.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.732249</td>\n",
       "      <td>0.464366</td>\n",
       "      <td>0.634774</td>\n",
       "      <td>0.689424</td>\n",
       "      <td>0.396397</td>\n",
       "      <td>0.636329</td>\n",
       "      <td>0.598004</td>\n",
       "      <td>0.574852</td>\n",
       "      <td>0.625444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>-3497.288048</td>\n",
       "      <td>-3331.281642</td>\n",
       "      <td>45.765203</td>\n",
       "      <td>-3394.721899</td>\n",
       "      <td>-0.013481</td>\n",
       "      <td>3394.721899</td>\n",
       "      <td>6.749174</td>\n",
       "      <td>351.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q</td>\n",
       "      <td>17</td>\n",
       "      <td>-3790.073549</td>\n",
       "      <td>-3653.392631</td>\n",
       "      <td>30.437155</td>\n",
       "      <td>-3703.890051</td>\n",
       "      <td>-0.008218</td>\n",
       "      <td>3703.890051</td>\n",
       "      <td>6.333221</td>\n",
       "      <td>348.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>-3810.950078</td>\n",
       "      <td>-3683.321617</td>\n",
       "      <td>35.116086</td>\n",
       "      <td>-3737.206895</td>\n",
       "      <td>-0.009396</td>\n",
       "      <td>3737.206895</td>\n",
       "      <td>6.486997</td>\n",
       "      <td>404.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558202</td>\n",
       "      <td>0.591124</td>\n",
       "      <td>0.658237</td>\n",
       "      <td>0.595267</td>\n",
       "      <td>0.661488</td>\n",
       "      <td>0.575933</td>\n",
       "      <td>0.565323</td>\n",
       "      <td>0.714385</td>\n",
       "      <td>0.763491</td>\n",
       "      <td>0.846974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V</td>\n",
       "      <td>22</td>\n",
       "      <td>-3902.100492</td>\n",
       "      <td>-3756.836505</td>\n",
       "      <td>36.499483</td>\n",
       "      <td>-3811.941937</td>\n",
       "      <td>-0.009575</td>\n",
       "      <td>3811.941937</td>\n",
       "      <td>6.292202</td>\n",
       "      <td>345.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_index      ch1_min      ch1_max    ch1_std     ch1_mean  \\\n",
       "0     I            9 -3464.721556 -3318.384685  34.719767 -3372.674790   \n",
       "1     F            6 -3497.288048 -3331.281642  45.765203 -3394.721899   \n",
       "2     Q           17 -3790.073549 -3653.392631  30.437155 -3703.890051   \n",
       "3     D            4 -3810.950078 -3683.321617  35.116086 -3737.206895   \n",
       "4     V           22 -3902.100492 -3756.836505  36.499483 -3811.941937   \n",
       "\n",
       "   ch1_coefficient_variation  ch1_mean_abs   ch1_AAC  ch1_CARD  ...  \\\n",
       "0                  -0.010294   3372.674790  7.005015     403.0  ...   \n",
       "1                  -0.013481   3394.721899  6.749174     351.0  ...   \n",
       "2                  -0.008218   3703.890051  6.333221     348.0  ...   \n",
       "3                  -0.009396   3737.206895  6.486997     404.0  ...   \n",
       "4                  -0.009575   3811.941937  6.292202     345.0  ...   \n",
       "\n",
       "   ch7_coherence  ch8_coherence  ch9_coherence  ch10_coherence  \\\n",
       "0       0.474576       0.732249       0.464366        0.634774   \n",
       "1       1.000000       1.000000       1.000000        1.000000   \n",
       "2       1.000000       1.000000       1.000000        1.000000   \n",
       "3       0.558202       0.591124       0.658237        0.595267   \n",
       "4       1.000000       1.000000       1.000000        1.000000   \n",
       "\n",
       "   ch11_coherence  ch12_coherence  ch13_coherence  ch14_coherence  \\\n",
       "0        0.689424        0.396397        0.636329        0.598004   \n",
       "1        1.000000        1.000000        1.000000        1.000000   \n",
       "2        1.000000        1.000000        1.000000        1.000000   \n",
       "3        0.661488        0.575933        0.565323        0.714385   \n",
       "4        1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "   ch15_coherence  ch16_coherence  \n",
       "0        0.574852        0.625444  \n",
       "1        1.000000        1.000000  \n",
       "2        1.000000        1.000000  \n",
       "3        0.763491        0.846974  \n",
       "4        1.000000        1.000000  \n",
       "\n",
       "[5 rows x 1122 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(feature_path+\"eeg_features/aat_img.csv\")\n",
    "df2.to_csv(feature_path+\"eeg_features/aat_vision.csv\")\n",
    "df3.to_csv(feature_path+\"eeg_features/asl_img.csv\")\n",
    "df4.to_csv(feature_path+\"eeg_features/asl_vision.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read those csv files instead of calculating the process above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is difficult to compare whether there are duplicate features, so we skip this function\n",
    "# I will check manually when I write the feature description and sort eeg_feature.py' function\n",
    "def compute_two_features():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annex - EEG feature description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A preliminary rough feature type classification\n",
    "\n",
    "* name/abbreviation, description, corresponding function\n",
    "\n",
    "To be aware of, not all the features are in our DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw features, statistical features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "min, min amplitude value, min_X() in eeg_features.py\n",
    "max, max amplitude value, max_X() in eeg_features.py\n",
    "mean, mean amplitude value, max_X() in eeg_features.py   \n",
    "median, median amplitude value, median_X() in eeg_features.py \n",
    "std, standard deviation of the time series, std_X() in eeg_features.py \n",
    "var, variance of the signals, var_X() in eeg_features.py \n",
    "coefficient_variation, relative standard deviation, coefficient_variation() in eeg_features.py \n",
    "mean_abs, mean absolute amplitude value, mean_absolute_X() in eeg_features.py\n",
    "AAC, average amplitude change, average_amplitude_change() in eeg_features.py \n",
    "CARD, cardinality of the time series, cardinality(X, thres=0.01) in eeg_features.py \n",
    "EMAV,enhanced mean absolute amplitude value, enhanced_mean_absolute() in eeg_features.py \n",
    "MAP, mean amplitude power, mean_amplitude_power() in eeg_features.py \n",
    "waveform_length, waveform/signal length, waveform_length() in eeg_features.py \n",
    "EML, enhanced wave length but always nan in our case, enhanced_wave_length() in eeg_features.py \n",
    "MCL, mean curve length, mean_curve_length() in eeg_features.py \n",
    "peak, the number of peaks in the signals, peak_X() in eeg_features.py\n",
    "num_zero_crossing, number of zero crossing, num_zero_crossing() in eeg_features.py\n",
    "spikes, signal amplitude exceeds μ by 3σ for 70 ms or less, spikeNum() in EEGExtract.py\n",
    "sharp_spikes, spikes lasting less than 70 ms, shortSpikeNum() in EEGExtract.py\n",
    "num_burst, number of amplitude bursts, numBursts() in EEGExtract.py\n",
    "burst_length_x, statistical properties of bursts-mean std, burstLengthStats() in EEGExtract.py\n",
    "supressions, segments with contiguous amplitude suppression, numSuppressions() in EEGExtract.py\n",
    "supressions_length_x, statistical properties of suppressions-mean std, suppressionLengthStats() in EEGExtract.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher-order statistical features, signal features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "totalVariation, total variation of the signals, totalVariation() in eeg_features.py\n",
    "LRSSV, log root sum of sequential variation, log root sum of sequential variation() in eeg_features.py\n",
    "1_x_diff, sum mean max min median values of the fisrt order difference, first_order_diff() in eeg_features.py \n",
    "2_x_diff, sum mean max min median values of the second order difference, second_order_diff() in eeg_features.py \n",
    "skew, skewness, skew_X() in eeg_features.py \n",
    "kurtosis, kurtosis, kurs_X() in eeg_features.py \n",
    "rms,root mean square(analyze noise), rms_X() in eeg_features.py \n",
    "PAPR, peak-to-average ratio, papr_X() in eeg_features.py \n",
    "hurst, hurst exponent of the time series, Hurst() in eeg_features.py \n",
    "PFD, Petrosian fractal dimension values, Petrosian_FD() in eeg_features.py \n",
    "hjorth_x, hjorth activity mobility(mean frequency) complexity, Hjorth() in eeg_features.py \n",
    "KFD, katz fractal dimension, KFD() in eeg_features.py \n",
    "HFD, higuchi fractal dimension, HFD() in eeg_features.py \n",
    "DFA, detrended  fluctuation analysis, DFA() in eeg_features.py \n",
    "LCZ, Lempel-Ziv Complexity, LCZ() in eeg_features.py \n",
    "LLE, lagest lyauponov exponent but nan in our case, LLE() in eeg_features.py \n",
    "lyapunov_exponent, separation between signals with similar trajectories, lyapunov() in EEGExtract.py\n",
    "FNN, False Nearest Neighbor-signal continuity and smoothness, falseNearestNeighbor() in EEGExtract.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### energy, entropy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "signal_energy, signal's energy. Could be computed also in the frequency domain (area under the power spectrum curve), signal_energy() in eeg_features.py \n",
    "mean_energy, mean energy of the signal-np.mean(X^2), mean_energy() in eeg_features.py \n",
    "mean_target_energy, mean teager energy(wrong name in DF), mean_teager_energy() in eeg_features.py\n",
    "log_energy_entropy, log energy entropy, log_energy_entropy() in eeg_features.py \n",
    "renyi_entropy, renyi entropy, renyi_entropy(X, alpha=2) in eeg_features.py \n",
    "wavelet_entropy, calculated after level 5 wavelet decomposition, wavelet_entropy() in eeg_features.py \n",
    "sample_entropy, sample entropy, sample_entropy() in eeg_features.py \n",
    "ant_permutation_entropy, calculate permutation entropy by ant, permutation_entropy() in eeg_features.py \n",
    "shannon_entropy, shannon entropy, shannon_entropy() in eeg_features.py \n",
    "spectral_entropy, spectral entropy by welch, spectral_entropy() in eeg_features.py \n",
    "svd_entropy, SVD entropy, svd_entropy() in eeg_features.py \n",
    "approximate_entropy, approximate entropy, approximate_entropy() in eeg_features.py \n",
    "tsalis_entropy, 1 order tsalis entropy, tsalisEntropy(order) in EEGExtract.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some features in the frequency domain"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wavelet_power, 5 level wavelet power band but not using, relativePower() in eeg_features.py \n",
    "pb_x, welch power band for delta theta alpha beta gamma, one_signal_band_power() in tools.py\n",
    "alpha/delta, ratio of the power spectral density in α and δ bands, calculate directly\n",
    "PB_SE_x, shannon entropy of each subband power, shannonEntropy() in EEGExtract.py\n",
    "cepstrum_x, rate of change in signal spectral band power, mfcc() in EEGExtract.py\n",
    "median_frequency, the median spectral power, medianFreq() in EEGExtract.py\n",
    "regularity (burst-suppression), measure of signal stationarity / spectral consistency, eegRegularity() in EEGExtract.py\n",
    "diffuse_slowing, indicator of peak power spectral density less than 8Hz, diffuseSlowing() in EEGExtract.py\n",
    "coherence, correlation in overall power between signals,  coherence() in EEGExtract.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
